{"config":{"lang":["ja"],"separator":"[\\s\\-\uff0c\u3002]+","pipeline":["stemmer"]},"docs":[{"location":"","title":"Kubean","text":"<p>kubean is a cluster lifecycle management tool based on kubespray.</p>"},{"location":"#awesome-features","title":"Awesome features","text":"<ul> <li>Simplicity: Deploying of Kubean and powerful lifecycle management of kubernetes cluster implementing by declarative API.</li> <li>Offline Supported: Offline packages(os-pkgs, images, binarys) are released with the release. You won't have to worry about how to gather all the resources you need.</li> <li>Compatibility: Multi-arch delivery Supporting. Such as AMD, ARM with common Linux distributions. Also include Kunpeng with Kylin.</li> <li>Expandability: Allowing custom actions be added to cluster without any changes for Kubespray. </li> </ul>"},{"location":"concepts/architecture/","title":"Kubean Infrastructure","text":"<p>The overall architecture of Kubean is shown below\uff1a</p> <p></p> <p>Kubean needs to run on an existing Kubernetes cluster. It controls and manages cluster lifecycle (install, uninstall, upgrade, scale up &amp; down, etc.) by applying the standard CRDs provided by Kubean and Kubernetes built-in resources. Kubean uses Kubespray as the underlying technology. On the one hand, it simplifies the operation process of cluster deployment and lowers the threshold of use. On the other hand, many new features such as cluster operation records and offline version records have been added on the basis of Kubespray's capabilities.</p> <p></p> <p></p> <p>Kubean runs several controllers to track changes of Kubean CRDs and communicates with the underlying cluster's API server to create Kubernetes native resources. It consists of four components\uff1a</p> <ol> <li>Cluster Controller: monitors 'Cluster Objects'. It uniquely identifies a cluster, has the access information, type information, and deployment parameter information of the cluster node, and is associated with all operations on the cluster ('ClusterOperation Objects');</li> <li>ClusterOperation Controller: monitors <code>ClusterOperation Objects</code>. When a <code>ClusterOperation Object</code> is created, the controller assembles a Job to perform the operations defined in the CRD object;</li> <li>Manifest Controller: monitors <code>Manifest Objects</code>. It records and maintains components, packages and versions that are used by or compatible with the current version of Kubean;</li> <li>LocalArtifactSet Controller\uff1amonitors <code>LocalArtifactSet Objects</code>. It records information about the components and versions supported by the offline package.</li> </ol>"},{"location":"concepts/comparisons/","title":"Kubean vs Kubespray","text":"<p>Kubespray uses Ansible as the underlying layer to configure and orchestrate clusters. It can run on bare metal machines, virtual machines, and most kinds of cloud environment. It supports a wide range of Kubernetes versions and various plugins. With Kubespray, you can flexibly build and configure clusters from 0 to 1, and maintain you clusters through their lifecycles.</p> <p>Kubean is based on Kubespray and boasts all the advantages of Kubespray. Moreover, Kubean introduces the concept of Operator to fully implement the philosophy of cloud native. Kubean is designed to run as a container, and can be easily installed with a Helm chart.</p> <p>Kubespray only supports offline at the parameter level and provides no process for building an offline install package, making it very troublesome for users who need to use it offline. They may gradually lose patience with Kubespray.</p> <p>Kubean not only has a mature workflow for making offline packages, it also simplifies Kubespray's configuration, allowing users to manage cluster life cycle in a cloud-native way.</p>"},{"location":"concepts/crds/","title":"CRDs","text":"<p>CustomResourceDefinition (CRD) is a Kubernetes built-in resource for creating custom resources to further extend the Kubernetes API. Kubean provides four built-in CRDs: Cluster, ClusterOperation, Manifest, and LocalArtifact.</p>"},{"location":"concepts/crds/#cluster","title":"Cluster","text":"<p>In Kubean, you can declare (uniquely identify) a Kubernetes cluster with a <code>Cluster</code> CRD. Clusters will be deployed according to their <code>Cluster</code> CRDs.</p> <p>Here's an example of the <code>Cluster</code> CRD:</p> <pre><code>apiVersion: kubean.io/v1alpha1\nkind: Cluster\nmetadata:\nname: cluster1-offline-demo\nspec:\nhostsConfRef:\nnamespace: kubean-system\nname: cluster1-offline-demo-hosts-conf\nvarsConfRef:\nnamespace: kubean-system\nname: cluster1-offline-demo-vars-conf\n</code></pre> <p>Each field in this CRD is explained as follows:</p>"},{"location":"concepts/crds/#metadata-section","title":"Metadata Section","text":"<ul> <li><code>name</code>: declares a globally unique cluster.</li> </ul>"},{"location":"concepts/crds/#spec-section","title":"Spec Section","text":"<ul> <li> <p><code>hostConfRef</code>: a ConfigMap resource in the format of ansible inventory. It includes information about nodes in a cluster, types, and groups. For further details, refer to demo.</p> </li> <li> <p><code>name</code>: name of the ConfigMap referenced by <code>hostConfRef</code>.</p> </li> <li> <p><code>namespace</code>: namespace of the ConfigMap referenced by <code>hostConfRef</code>.</p> </li> <li> <p><code>varsConfRef</code>: a ConfigMap resource to initialize or override variable values declared in Kubespray. This is very useful if you need to execute actions offline. For its specific content, refer to demo.</p> </li> <li> <p><code>name</code>: name of the ConfigMap referenced by <code>varsConfRef</code>.</p> </li> <li> <p><code>namespace</code>: namespace of the ConfigMap referenced by <code>varsConfRef</code>.</p> </li> <li> <p><code>sshAuthRef</code>: a Secret resource used only in the SSH private key mode.</p> </li> <li> <p><code>name</code>: name of the Secret referenced by <code>sshAuthRef</code>.</p> </li> <li><code>namespace</code>: namespace of the Secret referenced by <code>sshAuthRef</code>.</li> </ul>"},{"location":"concepts/crds/#clusteroperation","title":"ClusterOperation","text":"<p>In Kubean, you can declare actions (deployment, upgrade, etc.) against a Kubernetes cluster with a <code>ClusterOperation</code> CRD. This CRD must be correctly associated with the corresponding <code>Cluster</code> CRD, which provides necessary information for executing these actions.</p> <p>Here's an example of the <code>ClusterOperation</code> CRD:</p> <pre><code>apiVersion: kubean.io/v1alpha1\nkind: ClusterOperation\nmetadata:\nname: cluster1-demo-ops-1\nspec:\ncluster: cluster1-demo\nimage: ghcr.m.daocloud.io/kubean-io/spray-job:latest\nbackoffLimit: 0\nactionType: playbook\naction: cluster.yml\npreHook:\n- actionType: playbook\naction: ping.yml\n- actionType: playbook\naction: disable-firewalld.yml\npostHook:\n- actionType: playbook\naction: kubeconfig.yml\n- actionType: playbook\naction: cluster-info.yml\n</code></pre> <p>Each field in this CRD is explained as follows:</p>"},{"location":"concepts/crds/#metadata-section_1","title":"Metadata Section","text":"<ul> <li><code>name</code>: uniquely identifies an action against the associated cluster.</li> </ul>"},{"location":"concepts/crds/#spec","title":"Spec","text":"<ul> <li><code>cluster</code>: name of the cluster against which this action will be executed. It should be the same as the value declared in the Cluster CRD.</li> <li><code>image</code>: address of the Kubespray image. You can use the image in the Kubean repo or your own image.</li> <li><code>actionType</code>: type of the action. It currently can be set as either <code>playbook</code> or <code>shell</code>.</li> <li><code>action</code>: the action to be executed. It currently can be set as either a playbook file path or a shell command.</li> <li><code>preHook</code>: what should be done before executing the <code>action</code>. Allow multiple values, such as test connectivity.</li> <li><code>actionType</code>: refer to the above <code>actionType</code>.</li> <li><code>action</code>: refer to the above <code>action</code>.</li> <li><code>postHook</code>: what to do after executing the <code>action</code>. Allow multiple values, such as get the cluster status.</li> <li><code>actionType</code>: refer to the above <code>actionType</code>.</li> <li><code>action</code>: refer to the above <code>action</code>.</li> <li><code>backoffLimit</code>: times of retry if the <code>action</code> fails.</li> </ul>"},{"location":"concepts/crds/#manifest","title":"Manifest","text":"<p>In Kubean, you can use a <code>Manifest</code> CRD to create and maintain a record of components, packages, and versions used by or compatible with the current version of Kubean. You don't need to do this job manually. Kubean will take care of it for you.</p> <p>Here's an example of the <code>Manifest</code> CRD:</p> <pre><code>apiVersion: kubean.io/v1alpha1\nkind: Manifest\nmetadata:\nname: kubeaninfomanifest-v0-4-0-rc2\nspec:\ncomponents:\n- defaultVersion: v1.1.1\nname: cni\nversionRange:\n- v1.0.1\n- v1.1.1\n- defaultVersion: 1.6.9\nname: containerd\nversionRange:\n.......\n- 1.6.7\n- 1.6.8\n- 1.6.9\n- defaultVersion: \"\"\nname: kube\nversionRange:\n- v1.25.3\n- v1.25.2\n- v1.25.1\n........\n- defaultVersion: v3.23.3\nname: calico\nversionRange:\n- v3.23.3\n- v3.22.4\n- v3.21.6\n- defaultVersion: v1.12.1\nname: cilium\nversionRange: []\n- defaultVersion: \"null\"\nname: etcd\nversionRange:\n- v3.5.3\n- v3.5.4\n- v3.5.5\ndocker:\n- defaultVersion: \"20.10\"\nos: redhat-7\nversionRange:\n- latest\n- \"18.09\"\n- \"19.03\"\n- \"20.10\"\n- stable\n- edge\n- defaultVersion: \"20.10\"\nos: debian\nversionRange:\n- latest\n- \"18.09\"\n- \"19.03\"\n- \"20.10\"\n- stable\n- edge\n- defaultVersion: \"20.10\"\nos: ubuntu\nversionRange:\n- latest\n- \"18.09\"\n- \"19.03\"\n- \"20.10\"\n- stable\n- edge\nkubeanVersion: v0.4.0-rc2\nkubesprayVersion: c788620\n</code></pre> <p>Each field in this CRD is explained as follows:</p> <ul> <li><code>components</code>: declares versions of images or binary files.</li> <li><code>name</code>: name of a component.</li> <li><code>defaultVersion</code>: default versions of the component.</li> <li><code>versionRange</code>: supported component versions.</li> <li><code>docker</code>: manages Docker versions.</li> <li><code>os</code>: supported operating systems.</li> <li><code>defaultVersion</code>: the default version used.</li> <li><code>versionRange</code>: supported versions.</li> <li><code>kubeanVersion</code>: version of Kubean.</li> <li><code>kubesprayVersion</code>: version of the Kubespray used in Kubean.</li> </ul>"},{"location":"concepts/crds/#localartifact","title":"LocalArtifact","text":"<p>In Kubean, you can use a <code>LocalArtifact</code> CRD to record components and their versions supported by Kubean's offline package. You don't need to do this job manually. Kubean will take care of it for you.</p> <p>Here's an example of the <code>LocalArtifact</code> CRD:</p> <pre><code>apiVersion: kubean.io/v1alpha1\nkind: LocalArtifactSet\nmetadata:\nname: offlineversion-20221101\nspec:\narch: [\"x86_64\"]\nkubespray: \"c788620\"\ndocker:\n- os: \"redhat-7\"\nversionRange:\n- \"18.09\"\n- \"19.03\"\n- \"20.10\"\n- os: \"debian\"\nversionRange: []\n- os: \"ubuntu\"\nversionRange: []\nitems:\n- name: \"cni\"\nversionRange:\n- v1.1.1\n- name: \"containerd\"\nversionRange:\n- 1.6.9\n- name: \"kube\"\nversionRange:\n- v1.24.7\n- name: \"calico\"\nversionRange:\n- v3.23.3\n- name: \"cilium\"\nversionRange:\n- v1.12.1\n- name: \"etcd\"\nversionRange:\n- v3.5.4\n</code></pre> <p>Each field in this CRD is explained as follows:</p> <ul> <li><code>arch</code>: a list of supported CPU architectures.</li> <li><code>kubespray</code>: Kubespray version used.</li> <li><code>docker</code>: manages Docker versions.</li> <li><code>os</code>: operating systems supported by Docker</li> <li><code>versionRange</code>: a list of supported Docker versions.</li> <li><code>items</code>: manages versions of other components.</li> <li><code>name</code>: name of a component.</li> <li><code>versionRange</code>: a list of supported versions of the component.</li> </ul>"},{"location":"concepts/custom_action/","title":"\u81ea\u5b9a\u4e49 Action","text":""},{"location":"concepts/custom_action/#_1","title":"\u52a8\u673a","text":"<p>\u5bf9\u4e8e\u4f7f\u7528\u8005\u6765\u8bb2\uff0cKubean \u548c Kubesprary \u7684\u4ea7\u7269\u90fd\u662f OCI \u955c\u50cf\u3001 helm chart \u53ca K8s manifests\u3002\u5728\u5df2\u62ff\u5230\u8fd9\u4e9b\u4ea7\u7269\u7684\u60c5\u51b5\u4e0b\u8981\u81ea\u5b9a\u4e49\u4e00\u4e9b\u64cd\u4f5c\uff0c\u4e5f\u80fd\u505a\u5230\uff0c\u4f46\u662f\u4f1a\u6bd4\u8f83\u590d\u6742\uff0c\u9700\u8981\u624b\u52a8\u4fee\u6539\u4e0d\u5c11\u7684\u914d\u7f6e\u3002\u5e0c\u671b\u80fd\u591f\u7b80\u5316\u8fd9\u4e00\u8fc7\u7a0b\u3002</p>"},{"location":"concepts/custom_action/#_2","title":"\u76ee\u6807","text":"<p>\u63d0\u4f9b\u4e00\u79cd\u4fbf\u6377\u7684\u65b9\u5f0f\u80fd\u591f\u8ba9\u4f7f\u7528\u8005\u4f7f\u7528\u4e00\u4e9b\u81ea\u5b9a\u4e49\u7684\u64cd\u4f5c\u6765\u67e5\u770b\u3001\u4fee\u6539\u548c\u63a7\u5236\u96c6\u7fa4\u8282\u70b9\u7684\u72b6\u6001\u3002</p>"},{"location":"concepts/custom_action/#crd","title":"CRD \u8bbe\u8ba1","text":"<ol> <li>\u589e\u52a0 ActionSource \u5b57\u6bb5\u4ee5\u58f0\u660e Action \u6765\u6e90\uff0c\u5176\u503c\u76ee\u524d\u652f\u6301\uff1a</li> <li> <p>builtin\uff08\u7f3a\u7701\u503c\uff09 </p> <p>\u8868\u660e\u4f7f\u7528 kubean \u5185\u5efa ansible playbook \u6216\u5728 manifest \u5185\u8054\u7684 shell \u811a\u672c</p> </li> <li> <p>configmap</p> <p>\u8868\u660e\u9700\u8981\u7684 ansible playbook \u6216 shell \u811a\u672c\u901a\u8fc7 \u5f15\u7528 K8s configmap \u6765\u83b7\u53d6</p> </li> <li> <p>\u589e\u52a0 ActionSourceRef \u5b57\u6bb5\u4ee5\u58f0\u660e\u5f53 ActionSource \u503c\u4e3a configmap \u65f6\u6240\u5f15\u7528\u7684\u8d44\u6e90\u5bf9\u8c61\uff0c\u4e14\u4ec5\u5f53 ActionSource \u4e3a configmap \u65f6\u6b64\u5b57\u6bb5\u624d\u751f\u6548\uff0c\u5176\u683c\u5f0f\u4e3a\uff1a     <pre><code>actionSourceRef:\nname: &lt;configmap name&gt;\nnamespace: &lt;namespace of configmap&gt;\n</code></pre></p> </li> </ol> <p>\u914d\u7f6e\u793a\u4f8b\uff1a <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\nname: cluster1-demo-myaction\nnamespace: kubean-system\ndata:\nmyplaybook.yml: |\n- hosts: k8s_cluster\ngather_facts: false\nbecome: yes\nany_errors_fatal: \"{{ any_errors_fatal | default(true) }}\"\ntasks:\n- name: Print inventory hostname\ndebug:\nmsg: \"inventory_hostname is {{ inventory_hostname }}\"\nhello.sh: |\necho \"hello world!\"\n---\napiVersion: kubean.io/v1alpha1\nkind: ClusterOperation\nmetadata:\nname: cluster1-demo-ops-1\nspec:\ncluster: cluster1-demo\nimage: ghcr.io/kubean-io/spray-job:latest\nbackoffLimit: 0\nactionType: playbook\naction: myplaybook.yml\nactionSource: configmap\nactionSourceRef:\nname: cluster1-demo-myaction\nnamespace: kubean-system\npreHook:\n- actionType: shell\naction: hello.sh\nactionSource: configmap\nactionSourceRef:\nname: cluster1-demo-myaction\nnamespace: kubean-system\n</code></pre></p>"},{"location":"concepts/theory_of_airgapped_package/","title":"Theory of Air-gapped packages","text":"<p>Kubean CI builds offline assets to install Kubernetes in air-gapped environment.</p> <p>NOTE: About usage for the offline assets, please refer to offline.md</p> <p>This chapter explains the theory how the air-gapped packages come from.</p> <ul> <li>Assets: Github Releases</li> <li>Major contents:</li> </ul> Asset Description files-*.tar.gz The binaries required in Kubespray installation: example : kubeadm, runc images-*.tar.gz The k8s cluster images as well as CNI images os-pkgs-${linux_distribution}-${tag}.tar.gz deb/rpm required during k8s installion"},{"location":"concepts/theory_of_airgapped_package/#how-to-build-the-assets","title":"How to build the assets","text":"<ol> <li>Images &amp; binaries</li> </ol> <p>As stated in Kubespray offline deployment guide,    Kubespray already provides scripts to generate images and binaries list. (Thanks to great Kubespray! )</p> <p>With help of Kubespray script to generate binaries &amp; images list,    then we can use manage-offline-files.sh to download those binaries and images.    At last, Kubean provides an offline-build.sh to make them together.</p> <ol> <li>os-packages (deb/rpm)</li> </ol> <p>During the k8s installation, a few packages could not be installed as binaries, so we have to install them via deb/rpm.    The os packages list defines what packages will be involved.</p> <p>Github Action will build packages in different OS (as Qemu) via <code>dnf/apt</code> to download and archive RPM/DEB packages.</p> <ol> <li>CI process</li> </ol> <p>The offline assets are generated/managed by Github Action scripts.</p>"},{"location":"develop/roadmap/","title":"Kubean Roadmap","text":"<p>The current Roadmap is tentative, and the exact schedule depends on the needs of the community.</p> <p>For features not mentioned in the Roadmap, we can discuss them in the issues.</p>"},{"location":"develop/roadmap/#q3-2022","title":"Q3 2022","text":"<ul> <li>Kubean Project Architecture Process Design architecture.md</li> <li>Verify Kubean's cluster lifecycle management operations</li> <li>Adding OS packages to build CI https://github.com/kubean-io/kubean/pull/62</li> <li>Provides Kubean API https://github.com/kubean-io/kubean/pull/128</li> </ul>"},{"location":"develop/roadmap/#q4-2022","title":"Q4 2022","text":"<ul> <li>E2E tests kubean test case</li> <li>k8s images and binary packages support the arm architecture https://github.com/kubean-io/kubean/pull/200</li> <li>Support for upgrade package builds https://github.com/kubean-io/kubean/pull/289</li> <li>Offline scenario RHEL8.4 deployment adaptation https://github.com/kubean-io/kubean/pull/325</li> <li>Support for restore package manager configuration https://github.com/kubean-io/kubean/pull/298</li> <li>Support for backporting Kubeconfig after cluster deployment https://github.com/kubean-io/kubean/pull/192</li> <li>Add SSH Key authentication deployment method https://github.com/kubean-io/kubean/pull/302</li> </ul>"},{"location":"develop/roadmap/#q1-2023","title":"Q1 2023","text":"<ul> <li>Support for apt package manager configuration https://github.com/kubean-io/kubean/pull/459</li> <li>Support for Custom Actions for Cluster Operation CRD https://github.com/kubean-io/kubean/issues/361</li> <li>Kubean chart supports charts-syncer https://github.com/kubean-io/kubean/pull/468</li> <li>Add pre-testing before deployment https://github.com/kubean-io/kubean/pull/555</li> <li>Uniontech V20 1020a linux Adaptation https://github.com/kubean-io/kubean/pull/583</li> </ul>"},{"location":"develop/roadmap/#q2-2023","title":"Q2 2023","text":"<ul> <li>Support for OpenEuler-based cluster deployments https://github.com/kubean-io/kubean/pull/628</li> <li>Support for cluster deployment of other linux OS</li> <li>E2E CI Optimization</li> <li>Add checksum file for Assets in the release</li> <li>Supports multi-arch deployments with Join different architecture nodes</li> </ul>"},{"location":"releases/v0.4.0/","title":"V0.4.0","text":""},{"location":"releases/v0.4.0/#whats-changed","title":"What's Changed","text":"<ul> <li>update docker os-pkg version by @hangscer8 in https://github.com/kubean-io/kubean/pull/262</li> <li>cluster info with more retry time by @hangscer8 in https://github.com/kubean-io/kubean/pull/261</li> <li>Manifest crd support multi image repo by @hangscer8 in https://github.com/kubean-io/kubean/pull/266</li> <li>update kubespray default version to v1.24.7 by @ErikJiang in https://github.com/kubean-io/kubean/pull/272</li> <li>Disable cn proxy sources to improve kubean image build efficiency by @ErikJiang in https://github.com/kubean-io/kubean/pull/273</li> <li>fix e2e by @wenting-guo in https://github.com/kubean-io/kubean/pull/267</li> <li>add dasu23 into approvers by @YunShiHang in https://github.com/kubean-io/kubean/pull/275</li> <li>Update offline doc by @ErikJiang in https://github.com/kubean-io/kubean/pull/276</li> <li>Fix temporary version tag issues by @YunShiHang in https://github.com/kubean-io/kubean/pull/281</li> <li>add version constraints of dependencies in offline case by @tu1h in https://github.com/kubean-io/kubean/pull/274</li> <li>[chroe] Improve the install trivy method by @SSmallMonster in https://github.com/kubean-io/kubean/pull/282</li> <li>add certificated logo by @wenting-guo in https://github.com/kubean-io/kubean/pull/284</li> <li>adjust generate_offline_package to multi harbor projects by @hangscer8 in https://github.com/kubean-io/kubean/pull/285</li> <li>Unified k8s version by @ErikJiang in https://github.com/kubean-io/kubean/pull/286</li> <li>Update README badge by @ErikJiang in https://github.com/kubean-io/kubean/pull/287</li> <li>Add Dockerfile for airgap-patch by @hangscer8 in https://github.com/kubean-io/kubean/pull/289</li> <li>Add os package for ubuntu by @ErikJiang in https://github.com/kubean-io/kubean/pull/291</li> <li>rename ansible_ssh_pass to ansible_password by @tu1h in https://github.com/kubean-io/kubean/pull/290</li> <li>rename doc folder to docs by @tu1h in https://github.com/kubean-io/kubean/pull/293</li> <li>Add Doc For Airgap Patch by @hangscer8 in https://github.com/kubean-io/kubean/pull/294</li> <li>fix pr e2e fail by @wenting-guo in https://github.com/kubean-io/kubean/pull/288</li> <li>Support restore yum repo in enable-repo.yml by @ErikJiang in https://github.com/kubean-io/kubean/pull/298</li> <li>update &amp; add some docs by @tu1h in https://github.com/kubean-io/kubean/pull/299</li> <li>Add documentation for deploying clusters with ssh secret keys by @ErikJiang in https://github.com/kubean-io/kubean/pull/302</li> <li>Update doc for deploy cluster with ssh key by @ErikJiang in https://github.com/kubean-io/kubean/pull/306</li> <li>Add auto release notes ci by @YunShiHang in https://github.com/kubean-io/kubean/pull/309</li> <li>add os compatibility e2e by @wenting-guo in https://github.com/kubean-io/kubean/pull/310</li> <li>fix checkout repository bug by @YunShiHang in https://github.com/kubean-io/kubean/pull/311</li> <li>add unit test by @hangscer8 in https://github.com/kubean-io/kubean/pull/314</li> <li>chore: add ut by @yyzxw in https://github.com/kubean-io/kubean/pull/313</li> <li>fix airgap patch mod by @hangscer8 in https://github.com/kubean-io/kubean/pull/315</li> <li>import_iso support kylin v10 sp2 by @hangscer8 in https://github.com/kubean-io/kubean/pull/316</li> <li>Translation of kubean documents (issue305) by @yulng in https://github.com/kubean-io/kubean/pull/307</li> <li>upgrade kind version to 1.25.3 by @wenting-guo in https://github.com/kubean-io/kubean/pull/312</li> <li>[CI]add incremental packages by @YunShiHang in https://github.com/kubean-io/kubean/pull/317</li> <li>Update os_family for kylin in enable-repo playbook by @ErikJiang in https://github.com/kubean-io/kubean/pull/318</li> <li>Add os packages for kylin linux by @ErikJiang in https://github.com/kubean-io/kubean/pull/321</li> <li>Update os packages for kylin linux by @ErikJiang in https://github.com/kubean-io/kubean/pull/324</li> <li>Update the absolute path of the command in playbook by @ErikJiang in https://github.com/kubean-io/kubean/pull/326</li> <li>Offline adapation for RHEL 8.4 by @tu1h in https://github.com/kubean-io/kubean/pull/325</li> <li>fix Dockerfile.redhat8 by @tu1h in https://github.com/kubean-io/kubean/pull/327</li> <li>v0.4.1 Pre-release version by @ErikJiang in https://github.com/kubean-io/kubean/pull/329</li> </ul>"},{"location":"releases/v0.4.0/#new-contributors","title":"New Contributors","text":"<ul> <li>@tu1h made their first contribution in https://github.com/kubean-io/kubean/pull/274</li> <li>@SSmallMonster made their first contribution in https://github.com/kubean-io/kubean/pull/282</li> <li>@yulng made their first contribution in https://github.com/kubean-io/kubean/pull/307</li> </ul> <p>Full Changelog: https://github.com/kubean-io/kubean/compare/v0.3.7...v0.4.0</p>"},{"location":"releases/v0.4.1/","title":"V0.4.1","text":""},{"location":"releases/v0.4.1/#whats-changed","title":"What's Changed","text":"<ul> <li>Fix import_iso.sh by @tu1h in https://github.com/kubean-io/kubean/pull/330</li> <li>specify k8s version by @ErikJiang in https://github.com/kubean-io/kubean/pull/331</li> <li>Fix kylin linux offline deployment python3-libselinux dependency issue by @ErikJiang in https://github.com/kubean-io/kubean/pull/332</li> <li>translate sshkey_deploy_cluster.md by @Michelle951 in https://github.com/kubean-io/kubean/pull/323</li> <li>translate comparisons.md by @Michelle951 in https://github.com/kubean-io/kubean/pull/322</li> <li>translate crds.md to en by @Michelle951 in https://github.com/kubean-io/kubean/pull/320</li> <li>update packages.yml for kylin os by @ErikJiang in https://github.com/kubean-io/kubean/pull/335</li> <li>fix test by @hangscer8 in https://github.com/kubean-io/kubean/pull/334</li> <li>add release-process.md by @hangscer8 in https://github.com/kubean-io/kubean/pull/333</li> <li>Fix released image tag overrided by @tu1h in https://github.com/kubean-io/kubean/pull/336</li> <li>add offline-e2e by @wenting-guo in https://github.com/kubean-io/kubean/pull/341</li> <li>fix offline e2e workflow file by @wenting-guo in https://github.com/kubean-io/kubean/pull/342</li> <li>chart: namespace should go with release by @weizhoublue in https://github.com/kubean-io/kubean/pull/337</li> <li>update case md by @wenting-guo in https://github.com/kubean-io/kubean/pull/343</li> <li>Fix template rendering failure by @tu1h in https://github.com/kubean-io/kubean/pull/338</li> <li>fix offline workflow by @wenting-guo in https://github.com/kubean-io/kubean/pull/344</li> <li>fix offline shell by @wenting-guo in https://github.com/kubean-io/kubean/pull/345</li> <li>update airgap_patch image tag in doc by @hangscer8 in https://github.com/kubean-io/kubean/pull/349</li> <li>oprimize offline shell by @wenting-guo in https://github.com/kubean-io/kubean/pull/369</li> <li>optimize logs output by @hangscer8 in https://github.com/kubean-io/kubean/pull/362</li> <li>Optimize kubeanoperation spec.image tag by @hangscer8 in https://github.com/kubean-io/kubean/pull/371</li> <li>shihang.yun-fix-cd-bug by @YunShiHang in https://github.com/kubean-io/kubean/pull/374</li> <li>shihang.yun-optimize-input by @YunShiHang in https://github.com/kubean-io/kubean/pull/375</li> <li>fix cd image tag's bug by @YunShiHang in https://github.com/kubean-io/kubean/pull/376</li> <li>use kube-vip first by @hangscer8 in https://github.com/kubean-io/kubean/pull/379</li> <li>fix kubeconfig playbook by @hangscer8 in https://github.com/kubean-io/kubean/pull/380</li> <li>Reduce kubespray image size by @tu1h in https://github.com/kubean-io/kubean/pull/382</li> <li>allow custom kubean image repo in cd by @tu1h in https://github.com/kubean-io/kubean/pull/372</li> <li>fix arm image build failure by @tu1h in https://github.com/kubean-io/kubean/pull/384</li> <li>fix airgap-patch image build failure by @tu1h in https://github.com/kubean-io/kubean/pull/385</li> <li>Remove libselinux from os packages by @ErikJiang in https://github.com/kubean-io/kubean/pull/386</li> <li>Fix local Service yum repo by @hangscer8 in https://github.com/kubean-io/kubean/pull/387</li> <li>optimize offline-e2e environment set by @wenting-guo in https://github.com/kubean-io/kubean/pull/389</li> <li>add rhel7 ospkg by @tu1h in https://github.com/kubean-io/kubean/pull/390</li> <li>Check if the OS package needs to be rebuilt by @ErikJiang in https://github.com/kubean-io/kubean/pull/391</li> <li>Update get latest tag by @ErikJiang in https://github.com/kubean-io/kubean/pull/393</li> <li>Ready for release version v0.4.1 by @ErikJiang in https://github.com/kubean-io/kubean/pull/394</li> </ul>"},{"location":"releases/v0.4.1/#new-contributors","title":"New Contributors","text":"<ul> <li>@Michelle951 made their first contribution in https://github.com/kubean-io/kubean/pull/323</li> <li>@weizhoublue made their first contribution in https://github.com/kubean-io/kubean/pull/337</li> </ul> <p>Full Changelog: https://github.com/kubean-io/kubean/compare/v0.4.0...v0.4.1</p>"},{"location":"releases/v0.4.10/","title":"V0.4.10","text":""},{"location":"releases/v0.4.10/#whats-changed","title":"What's Changed","text":"<ul> <li>update redaht8 related e2e case by @wenting-guo in https://github.com/kubean-io/kubean/pull/654</li> <li>fix: ignore actionSourceRef not set by @jonyhy96 in https://github.com/kubean-io/kubean/pull/666</li> <li>optimize generate crds by @hangscer8 in https://github.com/kubean-io/kubean/pull/667</li> <li>add UT by @hangscer8 in https://github.com/kubean-io/kubean/pull/670</li> <li>kubean install on none kubean-system ns e2e by @wenting-guo in https://github.com/kubean-io/kubean/pull/672</li> <li>fix speedup offline package by @wenting-guo in https://github.com/kubean-io/kubean/pull/676</li> <li>[docs] update and translate theory-of-air-gapped-package.md by @windsonsea in https://github.com/kubean-io/kubean/pull/671</li> <li>cleanup: replace pkg ioutil with os by @yyzxw in https://github.com/kubean-io/kubean/pull/680</li> <li>update e2e case md by @wenting-guo in https://github.com/kubean-io/kubean/pull/683</li> <li>fix create job occasionally unsuccessfully  from ops by @hangscer8 in https://github.com/kubean-io/kubean/pull/684</li> <li>Fix ansible lint by @tu1h in https://github.com/kubean-io/kubean/pull/694</li> <li>Add kubean examples by @ErikJiang in https://github.com/kubean-io/kubean/pull/693</li> </ul> <p>Full Changelog: https://github.com/kubean-io/kubean/compare/v0.4.9...v0.4.10</p>"},{"location":"releases/v0.4.2/","title":"V0.4.2","text":""},{"location":"releases/v0.4.2/#whats-changed","title":"What's Changed","text":"<ul> <li>Update previous tag by @ErikJiang in https://github.com/kubean-io/kubean/pull/395</li> <li>remove preset playbook by @tu1h in https://github.com/kubean-io/kubean/pull/396</li> <li>fix enable-repo by @hangscer8 in https://github.com/kubean-io/kubean/pull/397</li> <li>Block the update repo from kylin os by @ErikJiang in https://github.com/kubean-io/kubean/pull/399</li> <li>Revert \"fix enable-repo\" by @hangscer8 in https://github.com/kubean-io/kubean/pull/400</li> <li>Remove unnecessary pkgs by @tu1h in https://github.com/kubean-io/kubean/pull/403</li> <li>Improve check_rebuild_pkgs by @tu1h in https://github.com/kubean-io/kubean/pull/404</li> <li>Restore os pkg by @tu1h in https://github.com/kubean-io/kubean/pull/411</li> <li>Revert \"Restore os pkg\" by @ErikJiang in https://github.com/kubean-io/kubean/pull/412</li> <li>Restore os pkg by @tu1h in https://github.com/kubean-io/kubean/pull/413</li> <li>add kylin os case by @wenting-guo in https://github.com/kubean-io/kubean/pull/416</li> <li>fix offline e2e bug by @wenting-guo in https://github.com/kubean-io/kubean/pull/417</li> <li>update pr ci yaml by @wenting-guo in https://github.com/kubean-io/kubean/pull/422</li> <li>make pr ci from vagrant to vm by @wenting-guo in https://github.com/kubean-io/kubean/pull/423</li> <li>add a parameter to pr ci workflow by @wenting-guo in https://github.com/kubean-io/kubean/pull/435</li> <li>add calico case in nightly e2e by @wenting-guo in https://github.com/kubean-io/kubean/pull/438</li> <li>add secrets for nightly e2e in workflow yaml by @wenting-guo in https://github.com/kubean-io/kubean/pull/445</li> <li>Add resources by @ErikJiang in https://github.com/kubean-io/kubean/pull/447</li> <li>update case md by @wenting-guo in https://github.com/kubean-io/kubean/pull/448</li> <li>update nightly e2e yaml by @wenting-guo in https://github.com/kubean-io/kubean/pull/449</li> <li>update kubean logo by @ErikJiang in https://github.com/kubean-io/kubean/pull/450</li> <li>update os compatibility e2e to vm by @wenting-guo in https://github.com/kubean-io/kubean/pull/451</li> <li>update nightly e2e passwd to secret by @wenting-guo in https://github.com/kubean-io/kubean/pull/455</li> <li>add secrets parameter in os compatibility workflow yaml by @wenting-guo in https://github.com/kubean-io/kubean/pull/456</li> <li>Remove versions.json by @tu1h in https://github.com/kubean-io/kubean/pull/452</li> <li>optimize hardcode namespace by @hangscer8 in https://github.com/kubean-io/kubean/pull/457</li> <li>Support import for ubuntu iso by @tu1h in https://github.com/kubean-io/kubean/pull/458</li> <li>Add spray job timeout by @hangscer8 in https://github.com/kubean-io/kubean/pull/462</li> <li>Remove fuse only in docker mode by @tu1h in https://github.com/kubean-io/kubean/pull/463</li> <li>add apt repo in enable-repo playbook by @ErikJiang in https://github.com/kubean-io/kubean/pull/459</li> <li>Update the check scripts for building os packages by @ErikJiang in https://github.com/kubean-io/kubean/pull/464</li> <li>fix  nightly e2e helm version set by @wenting-guo in https://github.com/kubean-io/kubean/pull/466</li> <li>support charts syncer by @ErikJiang in https://github.com/kubean-io/kubean/pull/468</li> <li>update restore apt condition in enable-repo playbook by @ErikJiang in https://github.com/kubean-io/kubean/pull/471</li> <li>Update action version for workflows by @ErikJiang in https://github.com/kubean-io/kubean/pull/474</li> <li>add redhat offline e2e by @wenting-guo in https://github.com/kubean-io/kubean/pull/475</li> <li>update case md by @wenting-guo in https://github.com/kubean-io/kubean/pull/476</li> <li>add unit test by @hangscer8 in https://github.com/kubean-io/kubean/pull/478</li> <li>set runner2 ip for e2e by @wenting-guo in https://github.com/kubean-io/kubean/pull/485</li> <li>update e2e k8s version to 1.24.7 by @wenting-guo in https://github.com/kubean-io/kubean/pull/489</li> <li>set nightly e2e and online os-compatibility-e2e to the online runner by @wenting-guo in https://github.com/kubean-io/kubean/pull/491</li> <li>Add ansible-lint for playbooks in pr gate by @tu1h in https://github.com/kubean-io/kubean/pull/483</li> <li>Support import offline resource parallelly by @tu1h in https://github.com/kubean-io/kubean/pull/482</li> <li>Fix job creating failure across different namespace by @tu1h in https://github.com/kubean-io/kubean/pull/488</li> <li>change upgrade e2e to vm by @wenting-guo in https://github.com/kubean-io/kubean/pull/492</li> <li>fix sa error by @cleverhu in https://github.com/kubean-io/kubean/pull/493</li> <li>change cluster lcm e2e case to vm by @wenting-guo in https://github.com/kubean-io/kubean/pull/497</li> <li>Get serviceaccount name by labelselector by @tu1h in https://github.com/kubean-io/kubean/pull/499</li> <li>add calico dual stack e2e by @wenting-guo in https://github.com/kubean-io/kubean/pull/500</li> <li>update online os compatibility run rate by @wenting-guo in https://github.com/kubean-io/kubean/pull/501</li> <li>support imageRepo with password by @hangscer8 in https://github.com/kubean-io/kubean/pull/502</li> <li>optimize ClusterRole &amp;&amp; set COMMIT_SHA for release by @hangscer8 in https://github.com/kubean-io/kubean/pull/506</li> <li>set kubespray commit by @hangscer8 in https://github.com/kubean-io/kubean/pull/507</li> </ul> <p>Full Changelog: https://github.com/kubean-io/kubean/compare/v0.4.1...v0.4.2</p>"},{"location":"releases/v0.4.3/","title":"V0.4.3","text":""},{"location":"releases/v0.4.3/#whats-changed","title":"What's Changed","text":"<ul> <li>rollback clusterrole by @hangscer8 in https://github.com/kubean-io/kubean/pull/511</li> <li>update minio repo by @wenting-guo in https://github.com/kubean-io/kubean/pull/512</li> <li>Fix incomplete ospkg cache judgment by @tu1h in https://github.com/kubean-io/kubean/pull/513</li> </ul> <p>Full Changelog: https://github.com/kubean-io/kubean/compare/v0.4.2...v0.4.3</p>"},{"location":"releases/v0.4.4/","title":"V0.4.4","text":""},{"location":"releases/v0.4.4/#whats-changed","title":"What's Changed","text":"<ul> <li>Remove ospkg buiding immediate exit by @tu1h in https://github.com/kubean-io/kubean/pull/514</li> <li>Fix import ospkgs script by @tu1h in https://github.com/kubean-io/kubean/pull/515</li> <li>Remove audit on rhel8 by @tu1h in https://github.com/kubean-io/kubean/pull/517</li> <li>add kubean maintainer by @wawa0210 in https://github.com/kubean-io/kubean/pull/519</li> <li>fix release image by @ErikJiang in https://github.com/kubean-io/kubean/pull/520</li> </ul>"},{"location":"releases/v0.4.4/#new-contributors","title":"New Contributors","text":"<ul> <li>@wawa0210 made their first contribution in https://github.com/kubean-io/kubean/pull/519</li> </ul> <p>Full Changelog: https://github.com/kubean-io/kubean/compare/v0.4.3...v0.4.4</p>"},{"location":"releases/v0.4.5/","title":"V0.4.5","text":""},{"location":"releases/v0.4.5/#whats-changed","title":"What's Changed","text":"<ul> <li>fix typo hack script for setup by @yanggangtony in https://github.com/kubean-io/kubean/pull/516</li> <li>chore: delete unused file #523 by @yyzxw in https://github.com/kubean-io/kubean/pull/526</li> <li>Fix offline e2e failure by @XiuguangHuang in https://github.com/kubean-io/kubean/pull/530</li> <li>Remove runc on offline rhel8 from playbook by @tu1h in https://github.com/kubean-io/kubean/pull/531</li> <li>fix imageRepo field by @panguicai008 in https://github.com/kubean-io/kubean/pull/534</li> <li>Update e2e_schedule.yaml by @XiuguangHuang in https://github.com/kubean-io/kubean/pull/536</li> <li>fix variable definition by @panguicai008 in https://github.com/kubean-io/kubean/pull/533</li> <li>fix spray-job container name by @hangscer8 in https://github.com/kubean-io/kubean/pull/537</li> <li>fix cluster status.conditions.startTime and endTime invalid value null by @panguicai008 in https://github.com/kubean-io/kubean/pull/538</li> <li>fix clusteroperation multi field invalid value null by @panguicai008 in https://github.com/kubean-io/kubean/pull/539</li> <li>Support custom action by @tu1h in https://github.com/kubean-io/kubean/pull/540</li> <li>Reduce centos7 package size by @yankay in https://github.com/kubean-io/kubean/pull/543</li> <li>Update CD about helm cmd vars by @tu1h in https://github.com/kubean-io/kubean/pull/546</li> <li>provide auto ci of k8s version compatibility by @XiuguangHuang in https://github.com/kubean-io/kubean/pull/547</li> <li>Support upgrade kubean CRDs by helm by @tu1h in https://github.com/kubean-io/kubean/pull/552</li> <li>Fix charts rendering exception by @tu1h in https://github.com/kubean-io/kubean/pull/554</li> <li>support pre-check playbook by @hangscer8 in https://github.com/kubean-io/kubean/pull/555</li> <li>Fix incorrect rendered template by @tu1h in https://github.com/kubean-io/kubean/pull/556</li> <li>optimize pre-check playbook by @hangscer8 in https://github.com/kubean-io/kubean/pull/559</li> <li>add ut by @hangscer8 in https://github.com/kubean-io/kubean/pull/560</li> <li>Set offline-pkg default k8s version to 1.25.4 by @hangscer8 in https://github.com/kubean-io/kubean/pull/564</li> <li>Add Others OS package build method by @ErikJiang in https://github.com/kubean-io/kubean/pull/561</li> <li>fix offline e2e and update iptables e2e test by @XiuguangHuang in https://github.com/kubean-io/kubean/pull/557</li> <li>fix main branch: auto-kubean-compatibility-schedule.yaml was modified incorrectly  by @XiuguangHuang in https://github.com/kubean-io/kubean/pull/563</li> <li>fix the wrong image tag when the main ci builds images. by @XiuguangHuang in https://github.com/kubean-io/kubean/pull/558</li> <li>Fix image name when push, and update the default k8s version to 1.26.0, fix kube_version of offline e2e  by @XiuguangHuang in https://github.com/kubean-io/kubean/pull/566</li> <li>add unit-test by @hangscer8 in https://github.com/kubean-io/kubean/pull/568</li> <li>support import iso for uniontech by @ErikJiang in https://github.com/kubean-io/kubean/pull/570</li> <li>add node affinity for chart by @ErikJiang in https://github.com/kubean-io/kubean/pull/571</li> <li>fix airgap patch image build and push by @XiuguangHuang in https://github.com/kubean-io/kubean/pull/572</li> <li>support unionTech for enable repo playbook by @ErikJiang in https://github.com/kubean-io/kubean/pull/575</li> <li>update anti affinity for kubean by @ErikJiang in https://github.com/kubean-io/kubean/pull/579</li> <li>set helm upgrade timeout and sprayJob tag by @XiuguangHuang in https://github.com/kubean-io/kubean/pull/578</li> <li>fix: update offline usage docs by @yyzxw in https://github.com/kubean-io/kubean/pull/577</li> <li>add theory-of-air-gapped-package by @panpan0000 in https://github.com/kubean-io/kubean/pull/582</li> <li>Update build script for UOS by @ErikJiang in https://github.com/kubean-io/kubean/pull/583</li> <li>optimize airgap patch by @hangscer8 in https://github.com/kubean-io/kubean/pull/584</li> <li>fix mv no such file in RHEL by @ErikJiang in https://github.com/kubean-io/kubean/pull/586</li> <li>optimize airgap patch image by @hangscer8 in https://github.com/kubean-io/kubean/pull/588</li> <li>change runner1 e2e ips by @XiuguangHuang in https://github.com/kubean-io/kubean/pull/589</li> <li>fix wrong tag of cd when running main ci by @XiuguangHuang in https://github.com/kubean-io/kubean/pull/581</li> <li>add call-cd params in main ci and release ci by @XiuguangHuang in https://github.com/kubean-io/kubean/pull/591</li> <li>add extra binary for airgap-patch by @hangscer8 in https://github.com/kubean-io/kubean/pull/592</li> <li>add create cilium cluster e2e test by @XiuguangHuang in https://github.com/kubean-io/kubean/pull/594</li> <li>remove registry.k8s.io/pause:3.4 by @hangscer8 in https://github.com/kubean-io/kubean/pull/595</li> </ul>"},{"location":"releases/v0.4.5/#new-contributors","title":"New Contributors","text":"<ul> <li>@XiuguangHuang made their first contribution in https://github.com/kubean-io/kubean/pull/530</li> <li>@panguicai008 made their first contribution in https://github.com/kubean-io/kubean/pull/534</li> <li>@panpan0000 made their first contribution in https://github.com/kubean-io/kubean/pull/582</li> </ul> <p>Full Changelog: https://github.com/kubean-io/kubean/compare/v0.4.4...v0.4.5</p>"},{"location":"releases/v0.4.6/","title":"V0.4.6","text":""},{"location":"releases/v0.4.6/#whats-changed","title":"What's Changed","text":"<ul> <li>clean unnecessary files by @hangscer8 in https://github.com/kubean-io/kubean/pull/597</li> <li>add debugger2 vms and debug cilium cluster by @wenting-guo in https://github.com/kubean-io/kubean/pull/598</li> <li>delete unused test case doc by @XiuguangHuang in https://github.com/kubean-io/kubean/pull/599</li> <li>Precheck Result Configmap by @hangscer8 in https://github.com/kubean-io/kubean/pull/600</li> <li>fix upgrade failed due to hard affinity by @ErikJiang in https://github.com/kubean-io/kubean/pull/601</li> <li>add cilium_kube_proxy_replacement by @XiuguangHuang in https://github.com/kubean-io/kubean/pull/605</li> <li>download offline files after release ci by @XiuguangHuang in https://github.com/kubean-io/kubean/pull/607</li> </ul> <p>Full Changelog: https://github.com/kubean-io/kubean/compare/v0.4.5...v0.4.6</p>"},{"location":"releases/v0.4.7/","title":"V0.4.7","text":""},{"location":"releases/v0.4.7/#whats-changed","title":"What's Changed","text":"<ul> <li>Fix incorrect data type on ActionSource by @tu1h in https://github.com/kubean-io/kubean/pull/613</li> </ul> <p>Full Changelog: https://github.com/kubean-io/kubean/compare/v0.4.6...v0.4.7</p>"},{"location":"releases/v0.4.8/","title":"V0.4.8","text":""},{"location":"releases/v0.4.8/#whats-changed","title":"What's Changed","text":"<ul> <li>add multi kubean operator e2e case by @XiuguangHuang in https://github.com/kubean-io/kubean/pull/608</li> <li>Update changes imported by pointer type by @tu1h in https://github.com/kubean-io/kubean/pull/618</li> </ul> <p>Full Changelog: https://github.com/kubean-io/kubean/compare/v0.4.7...v0.4.8</p>"},{"location":"releases/v0.4.9/","title":"V0.4.9","text":""},{"location":"releases/v0.4.9/#whats-changed","title":"What's Changed","text":"<ul> <li>fix download files job by @XiuguangHuang in https://github.com/kubean-io/kubean/pull/620</li> <li>fix remount iso by @hangscer8 in https://github.com/kubean-io/kubean/pull/624</li> <li>adding flannel\u3001kube-ovn to manifest cr by @cyclinder in https://github.com/kubean-io/kubean/pull/622</li> <li>[docs] add readme_zh.md by @windsonsea in https://github.com/kubean-io/kubean/pull/623</li> <li>Add code-of-conduct and CONTRIBUTING documentation by @tu1h in https://github.com/kubean-io/kubean/pull/625</li> <li>remove redundant docker os_pkgs by @hangscer8 in https://github.com/kubean-io/kubean/pull/626</li> <li>support openEuler by @hangscer8 in https://github.com/kubean-io/kubean/pull/628</li> <li>optimize import iso openeuler by @hangscer8 in https://github.com/kubean-io/kubean/pull/629</li> <li>support other linux in AirGap scenario by @ErikJiang in https://github.com/kubean-io/kubean/pull/627</li> <li>update pkgs.yml by @ErikJiang in https://github.com/kubean-io/kubean/pull/630</li> <li>fix unkonwn arch image by @ErikJiang in https://github.com/kubean-io/kubean/pull/631</li> <li>add openeuler ospkg by @hangscer8 in https://github.com/kubean-io/kubean/pull/632</li> <li>Support import ISO data to local path by @tu1h in https://github.com/kubean-io/kubean/pull/640</li> <li>Add Dependabot by @ErikJiang in https://github.com/kubean-io/kubean/pull/641</li> <li>Bump mikefarah/yq from 4.30.8 to 4.33.3 by @dependabot in https://github.com/kubean-io/kubean/pull/645</li> <li>Bump docker/build-push-action from 3.3.0 to 4.0.0 by @dependabot in https://github.com/kubean-io/kubean/pull/642</li> <li>Fix import_iso.sh by @tu1h in https://github.com/kubean-io/kubean/pull/651</li> <li>Bump docker/setup-buildx-action from 2.2.1 to 2.5.0 by @dependabot in https://github.com/kubean-io/kubean/pull/644</li> <li>Bump actions/setup-go from 3 to 4 by @dependabot in https://github.com/kubean-io/kubean/pull/643</li> <li>set pr-ci nightly-ci run time-limit to 15h by @wenting-guo in https://github.com/kubean-io/kubean/pull/653</li> <li>include dockerfile on ospkg cache judgment include by @tu1h in https://github.com/kubean-io/kubean/pull/655</li> <li>doc: fix english doc broken link by @jonyhy96 in https://github.com/kubean-io/kubean/pull/656</li> <li>add speedup offline packages by @wenting-guo in https://github.com/kubean-io/kubean/pull/657</li> <li>Add Roadmap by @ErikJiang in https://github.com/kubean-io/kubean/pull/661</li> <li>generate offline package for flannel by @cyclinder in https://github.com/kubean-io/kubean/pull/662</li> <li>add unsafe_show_logs to debug the download failed resource by @wenting-guo in https://github.com/kubean-io/kubean/pull/663</li> </ul>"},{"location":"releases/v0.4.9/#new-contributors","title":"New Contributors","text":"<ul> <li>@cyclinder made their first contribution in https://github.com/kubean-io/kubean/pull/622</li> <li>@dependabot made their first contribution in https://github.com/kubean-io/kubean/pull/645</li> <li>@jonyhy96 made their first contribution in https://github.com/kubean-io/kubean/pull/656</li> </ul> <p>Full Changelog: https://github.com/kubean-io/kubean/compare/v0.4.8...v0.4.9</p>"},{"location":"releases/v0.5.0/","title":"V0.5.0","text":""},{"location":"releases/v0.5.0/#whats-changed","title":"What's Changed","text":"<ul> <li>support oracle linux in offline enviroment by @ErikJiang in https://github.com/kubean-io/kubean/pull/700</li> </ul> <p>Full Changelog: https://github.com/kubean-io/kubean/compare/v0.4.10...v0.5.0</p>"},{"location":"releases/v0.5.1/","title":"V0.5.1","text":""},{"location":"releases/v0.5.1/#whats-changed","title":"What's Changed","text":"<ul> <li>remove dockerCE from openeuler pkgs by @hangscer8 in https://github.com/kubean-io/kubean/pull/706</li> <li>kubean e2e ci follow kubespray structure category by @tukwila in https://github.com/kubean-io/kubean/pull/707</li> <li>Fix KUBEAN_E2E_TEST_CI Error: A branch or tag with the name kubean_ci_test could not be found by @tukwila in https://github.com/kubean-io/kubean/pull/709</li> <li>fix kubean e2e ci not really run problem by @tukwila in https://github.com/kubean-io/kubean/pull/712</li> <li>Rename subdir api mod path by @hangscer8 in https://github.com/kubean-io/kubean/pull/715</li> <li>update other linux tool script by @ErikJiang in https://github.com/kubean-io/kubean/pull/716</li> <li>fix ci config variables by @tukwila in https://github.com/kubean-io/kubean/pull/718</li> <li>Update go mod dep version by @hangscer8 in https://github.com/kubean-io/kubean/pull/719</li> <li>add ipvs case by @wenting-guo in https://github.com/kubean-io/kubean/pull/714</li> <li>enable trivy security scanning by @hangscer8 in https://github.com/kubean-io/kubean/pull/721</li> <li>update enable repo playbook by @ErikJiang in https://github.com/kubean-io/kubean/pull/723</li> <li>add clean repolist in other linux script by @ErikJiang in https://github.com/kubean-io/kubean/pull/725</li> <li>update yum repo config in other linux by @ErikJiang in https://github.com/kubean-io/kubean/pull/726</li> <li>add mkdocs by @ErikJiang in https://github.com/kubean-io/kubean/pull/728</li> <li>update docs by @ErikJiang in https://github.com/kubean-io/kubean/pull/729</li> </ul> <p>Full Changelog: https://github.com/kubean-io/kubean/compare/v0.5.0...v0.5.1</p>"},{"location":"releases/v0.5.2-rc1/","title":"V0.5.2 rc1","text":""},{"location":"releases/v0.5.2-rc1/#whats-changed","title":"What's Changed","text":"<ul> <li>add module repo for yum manager by @ErikJiang in https://github.com/kubean-io/kubean/pull/730</li> </ul> <p>Full Changelog: https://github.com/kubean-io/kubean/compare/v0.5.1...v0.5.2-rc1</p>"},{"location":"releases/v0.5.2/","title":"V0.5.2","text":""},{"location":"releases/v0.5.2/#whats-changed","title":"What's Changed","text":"<ul> <li>add module repo for yum manager by @ErikJiang in https://github.com/kubean-io/kubean/pull/730</li> <li>CI failure:debug vm change to runner vm  by @yulng in https://github.com/kubean-io/kubean/pull/734</li> <li>update kube download url by @ErikJiang in https://github.com/kubean-io/kubean/pull/735</li> </ul> <p>Full Changelog: https://github.com/kubean-io/kubean/compare/v0.5.1...v0.5.2</p>"},{"location":"releases/v0.5.3/","title":"V0.5.3","text":""},{"location":"releases/v0.5.3/#whats-changed","title":"What's Changed","text":"<ul> <li>CI failure :change vm config and update docker rm command by @yulng in https://github.com/kubean-io/kubean/pull/740</li> <li>fetch os kernel version in precheck.yml by @hangscer8 in https://github.com/kubean-io/kubean/pull/739</li> <li>add ut by @hangscer8 in https://github.com/kubean-io/kubean/pull/741</li> <li>add kubean compatibility k8s version 1.27.1 by @wenting-guo in https://github.com/kubean-io/kubean/pull/743</li> <li>Update allinone.md by @yanrongshi in https://github.com/kubean-io/kubean/pull/749</li> <li>Support script import_iso.sh to load main function by @ErikJiang in https://github.com/kubean-io/kubean/pull/753</li> <li>Update README.md by @wawa0210 in https://github.com/kubean-io/kubean/pull/754</li> <li>add readme for docs by @ErikJiang in https://github.com/kubean-io/kubean/pull/755</li> <li>ignore pull pause 4 image by @ErikJiang in https://github.com/kubean-io/kubean/pull/756</li> </ul>"},{"location":"releases/v0.5.3/#new-contributors","title":"New Contributors","text":"<ul> <li>@yanrongshi made their first contribution in https://github.com/kubean-io/kubean/pull/749</li> </ul> <p>Full Changelog: https://github.com/kubean-io/kubean/compare/v0.5.2...v0.5.3</p>"},{"location":"releases/v0.5.4/","title":"V0.5.4","text":""},{"location":"releases/v0.5.4/#whats-changed","title":"What's Changed","text":"<ul> <li>remove alpha_arm by @hangscer8 in https://github.com/kubean-io/kubean/pull/759</li> <li>centos_cilium_online should use offline runner by @tukwila in https://github.com/kubean-io/kubean/pull/761</li> <li>e2e:update worker cluster k8s version by @yulng in https://github.com/kubean-io/kubean/pull/760</li> <li>update import iso by @ErikJiang in https://github.com/kubean-io/kubean/pull/762</li> </ul> <p>Full Changelog: https://github.com/kubean-io/kubean/compare/v0.5.3...v0.5.4</p>"},{"location":"usage/airgap/","title":"Use Kubean in offline scenes","text":""},{"location":"usage/airgap/#preparation","title":"Preparation","text":"<ol> <li>Services requiring pre-deployment:</li> <li>Document resource service <code>minio</code></li> <li> <p>Image registry services: <code>docker registry</code>\uff082.7 below\uff09   or <code>harbor</code></p> </li> <li> <p>Necessary tools to be installed:</p> </li> <li> <p>A tool for importing image files: <code>skopeo</code>, Required &gt;=1.9.2</p> </li> <li> <p>A tool for importing binary files: <code>minio client</code></p> </li> <li> <p>Deploy Kubean by Helm<code>kubean</code></p> </li> </ol>"},{"location":"usage/airgap/#download-offline-resources","title":"Download offline resources","text":"<p>The Github Releases page allows us to download the offline resources for the version we want</p> <p>Basic instructions for offline resources:</p> <pre><code>\u251c\u2500\u2500 files.list                                  # List of file contents\n\u251c\u2500\u2500 files-${tag}.tar.gz                         # File compression package, including import scripts\n\u251c\u2500\u2500 images.list                                 # List of image contents\n\u251c\u2500\u2500 images-${tag}.tar.gz                        # File compression package, including import scripts\n\u2514\u2500\u2500 os-pkgs-${linux_distribution}-${tag}.tar.gz # Compressed package of each system, including import script\n</code></pre>"},{"location":"usage/airgap/#importing-offline-resources-into-the-corresponding-service","title":"Importing offline resources into the corresponding service","text":""},{"location":"usage/airgap/#1-import-binary-resources","title":"1. Import binary resources","text":"<p>Please first unzip the <code>files-${tag}.tar.gz</code> file, which contains:</p> <pre><code>files/\n\u251c\u2500\u2500 import_files.sh       # This script is used to import binary files into the minio file service\n\u2514\u2500\u2500 offline-files.tar.gz  # Compressed package of binary \n</code></pre> <p>Execute the following command to import the binary file into the minio service:</p> <pre><code>$ MINIO_USER=${username} MINIO_PASS=${password} ./import_files.sh ${minio_address}\n</code></pre> <ul> <li><code>minio_address</code> is the <code>minio API Server</code> address, typically on port 9000, e.g. <code>http://1.2.3.4:9000</code></li> </ul>"},{"location":"usage/airgap/#2-images-import-of-resources","title":"2. Images  import of resources","text":"<p>You need to unzip the <code>images-${tag}.tar.gz</code> file, which contains:</p> <pre><code>images/\n\u251c\u2500\u2500 import_images.sh       # This script is used to import binary files into the minio file service\n\u2514\u2500\u2500 offline-images.tar.gz  # Compressed package of image file\n</code></pre> <p>Execute the following command to import the image file into the Docker Registry or the Harbor image repository service:</p> <pre><code># 1. Non-secure password-free mode\n$ DEST_TLS_VERIFY=false ./import_images.sh ${registry_address}\n\n# 2. Username password mode\n$ DEST_USER=${username} DEST_PASS=${password} ./import_images.sh ${registry_address}\n</code></pre> <ul> <li>When <code>DEST_TLS_VERIFY=false</code>, the image is uploaded in non-secure HTTP mode</li> <li><code>DEST_USER</code> and <code>DEST_PASS</code> need to be set when username and password authentication exists for the mirror repository</li> <li><code>registry_address</code> is the address of the mirror repository, e.g. <code>1.2.3.4:5000</code></li> </ul>"},{"location":"usage/airgap/#3-os-packages-import-of-resources","title":"3. OS packages import of resources","text":"<p>Note:  - OS Packages resources for Centos / Redhat / Kylin / Ubuntu distributions are currently supported. - The OS Package of UnionTech V20 series needs to be built manually, see README for the build method.</p> <p>You need to unzip the <code>os-pkgs-${linux_distribution}-${tag}.tar.gz</code> file, which contains:</p> <pre><code>os-pkgs\n\u251c\u2500\u2500 import_ospkgs.sh       # This script is used to import os packages to the minio file service\n\u251c\u2500\u2500 os-pkgs-amd64.tar.gz   # os packages for the amd64 architecture\n\u251c\u2500\u2500 os-pkgs-arm64.tar.gz   # os packages for the arm64 architecture\n\u2514\u2500\u2500 os-pkgs.sha256sum.txt  # The sha256sum checksum file for the os packages\n</code></pre> <p>Execute the following command to os packages into the minio file service:</p> <pre><code>$ MINIO_USER=${username} MINIO_PASS=${password} ./import_ospkgs.sh ${minio_address} os-pkgs-${arch}.tar.gz\n</code></pre>"},{"location":"usage/airgap/#create-offline-sources","title":"Create offline sources","text":""},{"location":"usage/airgap/#create-iso-image-source","title":"Create ISO image source","text":"<p>The following [Create local ISO image source] and [Create online ISO image source] only need to execute one of them.</p>"},{"location":"usage/airgap/#11-create-a-local-iso-image-source","title":"1.1 Create a local ISO image source","text":"<p>OS Packages are primarily used to resolve docker-ce installation dependencies, but for offline deployments, other packages from the distribution may be used, and a local ISO image source will need to be created.</p> <p>Note: We need to download the ISO system distribution image for the host in advance, currently only the ISO image source for the Centos distribution is supported; Note: This operation needs to be performed on each cluster that creates kubernetes nodes;</p> <p>The script <code>artifacts/gen_repo_conf.sh</code> can be used to mount the ISO image and create the Repo configuration file by executing the following command:</p> <pre><code># Basic format\n$ ./gen_repo_conf.sh --iso-mode ${linux_distribution} ${iso_image_file}\n\n# Execute the script to create the ISO image source\n$ ./gen_repo_conf.sh --iso-mode centos CentOS-7-x86_64-Everything-2207-02.iso\n# Check ISO image mounts\n$ df -h | grep mnt\n/dev/loop0               9.6G  9.6G     0 100% /mnt/centos-iso\n# Check ISO image source configuration\n$ cat /etc/yum.repos.d/Kubean-ISO.repo\n[kubean-iso]\nname=Kubean ISO Repo\nbaseurl=file:///mnt/centos-iso\nenabled=1\ngpgcheck=0\nsslverify=0\n</code></pre>"},{"location":"usage/airgap/#12-create-an-online-iso-image-source","title":"1.2 Create an online ISO image source","text":"<p>To import the image source from the ISO into the minio server, use the script <code>artifacts/import_iso.sh</code></p> <pre><code>MINIO_USER=${username} MINIO_PASS=${password} ./import_iso.sh ${minio_address} Centos-XXXX.ISO\n</code></pre> <p>Create the following file for the host <code>/etc/yum.repos.d/centos-iso-online.repo</code> to use the online ISO image source:</p> <pre><code>[kubean-iso-online]\nname=Kubean ISO Repo Online\nbaseurl=${minio_address}/kubean/centos-iso/$releasever/os/$basearch\nenabled=1\ngpgcheck=0\nsslverify=0\n</code></pre> <ul> <li>Need to replace <code>${minio_address}</code> with the minio API Server address</li> </ul>"},{"location":"usage/airgap/#2-create-extras-software-sources","title":"2. Create extras software sources","text":"<p>Currently only supported on Centos distributions</p> <p>When installing a K8S cluster, it also relies on extras, such as <code>container-selinux</code>, which are not always provided in the ISO image source. This is supplemented by the OS packages offline package, which requires us to create an extra repo configuration file for each node after importing minio.</p> <p>The Extra Repo can also be created using the script <code>artifacts/gen_repo_conf.sh</code>, by executing the following command:</p> <pre><code>$ ./gen_repo_conf.sh --url-mode ${linux_distribution} ${repo_base_url}\n\n# Execute the script to create a URL source profile\n$ ./gen_repo_conf.sh --url-mode centos ${minio_address}/kubean/centos/\\$releasever/os/\\$basearch\n# View URL source profile\n$ cat /etc/yum.repos.d/Kubean-URL.repo\n[kubean-extra]\nname=Kubean Extra Repo\nbaseurl=http://10.20.30.40:9000/kubean/centos/$releasever/os/$basearch\nenabled=1\ngpgcheck=0\nsslverify=0\n</code></pre> <p>Note: If the <code>repo_base_url</code> parameter has a <code>$</code> symbol, it needs to be escaped <code>\\$</code></p> <p>Need to replace <code>${minio_address}</code> with the actual <code>minio API Server</code> address</p>"},{"location":"usage/airgap/#3-clusteroperation-combined-with-playbook-to-create-source-profiles","title":"3. ClusterOperation combined with playbook to create source profiles","text":"<p>Only Centos yum repo additions are currently supported</p> <p>As the process of creating a source involves all the nodes in the cluster, manual scripting is relatively tedious, so a playbook solution is provided here:</p> <pre><code>apiVersion: kubean.io/v1alpha1\nkind: ClusterOperation\nmetadata:\nname: cluster-ops-01\nspec:\ncluster: sample\nimage: ghcr.io/kubean-io/spray-job:latest\nbackoffLimit: 0\nactionType: playbook\naction: cluster.yml\npreHook:\n- actionType: playbook\naction: ping.yml\n- actionType: playbook\naction: enable-repo.yml  # Before deploying the cluster, run the enable-repo playbook to create a source configuration for each node with the specified url\nextraArgs: |\n-e \"{repo_list: ['http://10.20.30.40:9000/kubean/centos/\\$releasever/os/\\$basearch']}\"\n- actionType: playbook\naction: disable-firewalld.yml\npostHook:\n- actionType: playbook\naction: cluster-info.yml\n- actionType: playbook\naction: enable-repo.yml  # After deploying the cluster, restore the yum repo configuration for each node. (Note: This step can be added as appropriate.)\nextraArgs: |\n-e undo=true\n</code></pre>"},{"location":"usage/airgap/#pre-deployment-cluster-configuration","title":"Pre-deployment cluster configuration","text":"<p>Offline settings need to be referred to <code>kubespray</code> Located in <code>kubespray/inventory/sample/group_vars/all/offline.yml</code> configuration file:</p> <pre><code>---\n## Global offline configuration\n### Configure the address of the private container image repository service\nregistry_host: \"{{ registry_address }}\"\n\n### Configuring the address of the binary file service\nfiles_repo: \"{{ minio_address }}/kubean\"\n\n### If you are using CentOS / RedHat / AlmaLinux / Fedora, you need to configure the yum source file service address:\nyum_repo: \"{{ minio_address }}\"\n\n### If using Debian, configure:\ndebian_repo: \"{{ minio_address }}\"\n\n### If using Ubuntu, configure:\nubuntu_repo: \"{{ minio_address }}\"\n\n### If containerd uses a non-secure HTTP authentication-free method, it needs to be configured:\ncontainerd_insecure_registries:\n\"{{ registry_address }}\": \"http://{{ registry_address }}\"\n\n### Required if docker uses non-secure HTTP authentication-free methods:\ndocker_insecure_registries:\n- {{ registry_address }}\n\n## Kubernetes components\nkubeadm_download_url: \"{{ files_repo }}/dl.k8s.io/release/{{ kubeadm_version }}/bin/linux/{{ image_arch }}/kubeadm\"\nkubectl_download_url: \"{{ files_repo }}/dl.k8s.io/release/{{ kube_version }}/bin/linux/{{ image_arch }}/kubectl\"\nkubelet_download_url: \"{{ files_repo }}/dl.k8s.io/release/{{ kube_version }}/bin/linux/{{ image_arch }}/kubelet\"\n\n## CNI Plugins\ncni_download_url: \"{{ files_repo }}/github.com/containernetworking/plugins/releases/download/{{ cni_version }}/cni-plugins-linux-{{ image_arch }}-{{ cni_version }}.tgz\"\n\n## cri-tools\ncrictl_download_url: \"{{ files_repo }}/github.com/kubernetes-sigs/cri-tools/releases/download/{{ crictl_version }}/crictl-{{ crictl_version }}-{{ ansible_system | lower }}-{{ image_arch }}.tar.gz\"\n\n## [Optional] etcd: only if you **DON'T** use etcd_deployment=host\netcd_download_url: \"{{ files_repo }}/github.com/etcd-io/etcd/releases/download/{{ etcd_version }}/etcd-{{ etcd_version }}-linux-{{ image_arch }}.tar.gz\"\n\n# [Optional] Calico: If using Calico network plugin\ncalicoctl_download_url: \"{{ files_repo }}/github.com/projectcalico/calico/releases/download/{{ calico_ctl_version }}/calicoctl-linux-{{ image_arch }}\"\ncalicoctl_alternate_download_url: \"{{ files_repo }}/github.com/projectcalico/calicoctl/releases/download/{{ calico_ctl_version }}/calicoctl-linux-{{ image_arch }}\"\n# [Optional] Calico with kdd: If using Calico network plugin with kdd datastore\ncalico_crds_download_url: \"{{ files_repo }}/github.com/projectcalico/calico/archive/{{ calico_version }}.tar.gz\"\n\n# [Optional] Flannel: If using Falnnel network plugin\nflannel_cni_download_url: \"{{ files_repo }}/kubernetes/flannel/{{ flannel_cni_version }}/flannel-{{ image_arch }}\"\n\n# [Optional] helm: only if you set helm_enabled: true\nhelm_download_url: \"{{ files_repo }}/get.helm.sh/helm-{{ helm_version }}-linux-{{ image_arch }}.tar.gz\"\n\n# [Optional] crun: only if you set crun_enabled: true\ncrun_download_url: \"{{ files_repo }}/github.com/containers/crun/releases/download/{{ crun_version }}/crun-{{ crun_version }}-linux-{{ image_arch }}\"\n\n# [Optional] kata: only if you set kata_containers_enabled: true\nkata_containers_download_url: \"{{ files_repo }}/github.com/kata-containers/kata-containers/releases/download/{{ kata_containers_version }}/kata-static-{{ kata_containers_version }}-{{ ansible_architecture }}.tar.xz\"\n\n# [Optional] cri-dockerd: only if you set container_manager: docker\ncri_dockerd_download_url: \"{{ files_repo }}/github.com/Mirantis/cri-dockerd/releases/download/v{{ cri_dockerd_version }}/cri-dockerd-{{ cri_dockerd_version }}.{{ image_arch }}.tgz\"\n\n# [Optional] runc,containerd: only if you set container_runtime: containerd\nrunc_download_url: \"{{ files_repo }}/github.com/opencontainers/runc/releases/download/{{ runc_version }}/runc.{{ image_arch }}\"\ncontainerd_download_url: \"{{ files_repo }}/github.com/containerd/containerd/releases/download/v{{ containerd_version }}/containerd-{{ containerd_version }}-linux-{{ image_arch }}.tar.gz\"\nnerdctl_download_url: \"{{ files_repo }}/github.com/containerd/nerdctl/releases/download/v{{ nerdctl_version }}/nerdctl-{{ nerdctl_version }}-{{ ansible_system | lower }}-{{ image_arch }}.tar.gz\"\n</code></pre> <p>For offline deployment, additional parameters are required for some special operating systems:</p> OS Additional parameters RHEL Series <code>rhel_enable_repos: false</code> Oracle Linux Series <code>use_oracle_public_repo: false</code> <p>We use <code>examples/install/3.airgap</code> as a template,</p> <p>Adapt the offline configuration as above to your specific situation, especially if you need to replace <code>&lt;registry_address&gt;</code> and <code>&lt;minio_address&gt;</code>,</p> <p>Finally add the configuration update to the <code>examples/install/3.airgap/VarsConfCM.yml</code>  file,</p> <p>We also need to change the cluster node IP and username password in <code>examples/install/3.airgap/HostsConfCM.yml</code>,</p> <p>Finally, the ClusterOperation task is started with <code>kubectl apply -f examples/install/3.airgap</code> to install the k8s cluster.</p>"},{"location":"usage/airgap/#generation-and-use-of-incremental-offline-packages","title":"Generation and use of incremental offline packages","text":"<p>For detailed documentation see: Air gap patch usage.</p>"},{"location":"usage/airgap_patch_usage/","title":"Generation and use of incremental offline packages","text":"<p>To meet users' needs for components of certain versions, Kubean provides the script <code>artifacts/offline_patch.py</code> to generate a corresponding version of offline packages based on the configuration file <code>manifest.yml</code>.</p>"},{"location":"usage/airgap_patch_usage/#generate-incremental-offline-packages","title":"Generate incremental offline packages","text":"<ol> <li>Create a new <code>manifest.yml</code> file in a folder, with the following example:</li> </ol> <pre><code>image_arch:\n- \"amd64\"\n- \"arm64\"\nkube_version:\n- \"v1.24.6\"\n- \"v1.24.4\"\ncalico_version:\n- \"v3.23.3\"\ncni_version:\n- \"v1.1.1\"\ncontainerd_version:\n- \"1.6.8\"\ncilium_version:\n- \"v1.12.1\"\netcd_version:\n- \"v3.5.3\"\n</code></pre> <ol> <li> <p>Create a new <code>data</code> folder in the same folder</p> </li> <li> <p>Run the following command to generate an incremental offline package in the <code>data</code> folder</p> <pre><code>docker run -v $(pwd)/manifest.yml:/manifest.yml -v $(pwd)/data:/data ghcr.io/hangscer8/airgap-patch:v0.2.0\n</code></pre> </li> </ol>"},{"location":"usage/airgap_patch_usage/#use-the-incremental-offline-package","title":"Use the incremental offline package:","text":"<p>The directory structure of the incremental package is as follows:</p> <pre><code>data\n\u2514\u2500\u2500 v_offline_patch\n    \u251c\u2500\u2500 amd64\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 files\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 import_files.sh\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 offline-files.tar.gz\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 images\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 import_images.sh\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 offline-images.tar.gz\n    \u251c\u2500\u2500 arm64\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 files\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 import_files.sh\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 offline-files.tar.gz\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 images\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 import_images.sh\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 offline-images.tar.gz\n    \u2514\u2500\u2500 kubeanofflineversion.cr.patch.yaml\n</code></pre> <p>(1). Write file data into MinIO</p> <pre><code>$ cd data/v_offline_patch/amd64/files\n\n$ MINIO_USER=${username} MINIO_PASS=${password} ./import_files.sh ${minio_address}\n</code></pre> <ul> <li><code>minio_address</code> is the <code>minio API Server</code> address, typically on port 9000, for example: <code>http://1.2.3.4:9000</code>.</li> </ul> <p>(2). Write image data to the docker registry (version 2.6.2 recommended) or harbor</p> <pre><code>$ cd data/v_offline_patch/amd64/images # 1. Non-secure password-free mode\n$ DEST_TLS_VERIFY=false ./import_images.sh ${registry_address}\n\n# 2. Username password mode\n$ DEST_USER=${username} DEST_PASS=${password} ./import_images.sh ${registry_address}\n</code></pre> <ul> <li>When <code>DEST_TLS_VERIFY=false</code>, the image is uploaded in non-secure HTTP mode.</li> <li><code>DEST_USER</code> and <code>DEST_PASS</code> need to be set when username and password authentication exists for the image registry.</li> <li><code>registry_address</code> is the address of the image registry, e.g. <code>1.2.3.4:5000</code>.</li> </ul> <p>(3). Write <code>kubeanofflineversion.cr.patch.yaml</code> to the k8s cluster</p> <pre><code>$ cd data/v_offline_patch\n$ kubectl apply -f kubeanofflineversion.cr.patch.yaml </code></pre> <ul> <li>This step is to inform the kubean-operator of the new software version available for offline use.</li> </ul>"},{"location":"usage/all-in-one-install/","title":"Minimal Deployment","text":""},{"location":"usage/all-in-one-install/#prerequisites","title":"Prerequisites","text":"<ol> <li>You have a standard Kubernetes cluster or a cluster provided by a cloud provider.</li> <li>The kubectl tool has been installed on your cluster control node or cloud terminal.</li> <li>The kubean helm chart has been deployed on your cluster.</li> <li>The kubean project has been cloned to your local machine. If you haven't cloned kubean yet, you can execute the following command to clone it:</li> </ol> <pre><code>$ git clone https://github.com/kubean-io/kubean.git\n</code></pre>"},{"location":"usage/all-in-one-install/#deployment","title":"Deployment","text":"<p>In this tutorial, we will use the <code>kubean/example</code> file cloned to your local machine as a template for demonstration purposes.</p> <p>With the help of the example template, we can use kubean to complete the deployment of a single-node cluster in just two steps.</p>"},{"location":"usage/all-in-one-install/#1-configure-the-allinoneyml-parameters","title":"1. Configure the AllInOne.yml parameters","text":"<p>Navigate to the <code>kubean/examples/install/1.minimal</code>  file path, edit the AllInOne.yml template for single-node mode deployment, and replace the following parameters with your actual parameters.</p> <ul> <li><code>&lt;IP1&gt;</code>: Node IP.</li> <li><code>&lt;USERNAME&gt;</code>: The username for logging into the node. It is recommended to use root or a user with root privileges to log in.</li> <li><code>&lt;PASSWORD&gt;</code>: The password for logging into the node.</li> <li><code>&lt;TAG&gt;</code>: kubean image version, it is recommended to use the latest version, Refer to the kubean version list.</li> </ul> <p>For example, the following shows an example of AllInOne.yml:</p> Example of AllInOne.yml <pre><code>---\napiVersion: v1\nkind: ConfigMap\nmetadata:\nname: mini-hosts-conf\nnamespace: kubean-system\ndata:\nhosts.yml: |\nall:\nhosts:\nnode1:\nip: 10.6.175.10 # Your node IP\naccess_ip: 10.6.175.10 # Your node IP\nansible_host: 10.6.175.10 # Your node IP\nansible_connection: ssh\nansible_user: root # The username for logging into the node\nansible_password: password01 # The password for logging into the node\nchildren:\nkube_control_plane:\nhosts:\nnode1:\nkube_node:\nhosts:\nnode1:\netcd:\nhosts:\nnode1:\nk8s_cluster:\nchildren:\nkube_control_plane:\nkube_node:\ncalico_rr:\nhosts: {}\n\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\nname: mini-vars-conf\nnamespace: kubean-system\ndata:\ngroup_vars.yml: |\ncontainer_manager: containerd\nkube_network_plugin: calico\netcd_deployment_type: kubeadm\n\n---\napiVersion: kubean.io/v1alpha1\nkind: Cluster\nmetadata:\nname: cluster-mini\nlabels:\nclusterName: cluster-mini\nspec:\nhostsConfRef:\nnamespace: kubean-system\nname: mini-hosts-conf\nvarsConfRef:\nnamespace: kubean-system\nname:  mini-vars-conf\n\n---\napiVersion: kubean.io/v1alpha1\nkind: ClusterOperation\nmetadata:\nname: cluster-mini-install-ops\nspec:\ncluster: cluster-mini\nimage: ghcr.m.daocloud.io/kubean-io/spray-job:v0.5.2 # kubean image version\nbackoffLimit: 0\nactionType: playbook\naction: cluster.yml\npreHook:\n- actionType: playbook\naction: disable-firewalld.yml\npostHook:\n- actionType: playbook\naction: cluster-info.yml\n</code></pre> <p>Execute the following command to edit the AllInOne.yml configuration template:</p> <pre><code>$ vi kubean/examples/install/1.minimal/AllInOne.yml\n</code></pre>"},{"location":"usage/all-in-one-install/#2apply-the-allinoneyml-configuration","title":"2.Apply the AllInOne.yml configuration","text":"<p>After completing the above steps and saving the AllInOne.yml file, execute the following command:</p> <pre><code>$ kubectl apply -f examples/install/1.minimal/AllInOne.yml\n</code></pre> <p>At this point, you have completed the deployment of a simple single-node cluster.</p>"},{"location":"usage/helm-install-kubean/","title":"Installing kubean Helm application","text":""},{"location":"usage/helm-install-kubean/#prerequisites","title":"Prerequisites","text":"<ol> <li>You have a standard Kubernetes cluster or a cluster provided by a cloud provider.</li> <li>Helm tool has been installed on your cluster control node or cloud terminal. How to install Helm tool</li> </ol>"},{"location":"usage/helm-install-kubean/#deployment","title":"Deployment","text":""},{"location":"usage/helm-install-kubean/#1-add-kubean-helm-repository","title":"1. Add kubean Helm repository","text":"<p>Add the kubean Helm repository to your local Helm repository by executing the following command on your existing cluster control node or cloud terminal.</p> <p><pre><code>$ helm repo add kubean-io https://kubean-io.github.io/kubean-helm-chart/\n</code></pre> After completing the previous step, check if the kubean repository has been added correctly to your local Helm repository.</p> <pre><code>$ helm repo list\n# Expected output:\nNAME            URL\nkubean-io       https://kubean-io.github.io/kubean-helm-chart/\n</code></pre>"},{"location":"usage/helm-install-kubean/#2-install-kubean","title":"2. Install kubean","text":"<p>Check the available charts and their versions in the kubean Helm repository by executing the following command, which will list all the charts available in the kubean Helm repository.</p> <pre><code>helm search repo kubean\n\n# Expected output:\nNAME                CHART VERSION   APP VERSION DESCRIPTION\nkubean-io/kubean    v0.5.2          v0.5.2      A Helm chart for kubean\n</code></pre> <p>After completing the above steps, execute the following command to install kubean.</p> <pre><code>$ helm install kubean kubean-io/kubean --create-namespace -n kubean-system\n</code></pre> <p>Note</p> <p>You can also use the \"--version\" parameter to specify the version of kubean.</p>"},{"location":"usage/helm-install-kubean/#3-view-installed-kubean-release","title":"3. View installed kubean release","text":"<p>You have now completed the deployment of the kubean Helm chart. You can execute the following command to view the helm release in the kubean-system namespace.</p> <pre><code>$ helm ls -n kubean-system\n\n# Expected output:\nNAME    NAMESPACE       REVISION    UPDATED                                     STATUS      CHART               APP VERSION\nkubean  kubean-system   1           2023-05-15 00:24:32.719770617 -0400 -0400   deployed    kubean-v0.4.9-rc1   v0.4.9-rc1\n</code></pre>"},{"location":"usage/install/","title":"\u96c6\u7fa4\u90e8\u7f72","text":"<p>\u524d\u7f6e\u6761\u4ef6\uff1a\u901a\u8fc7 helm \u5b89\u88c5 kubean charts.</p>"},{"location":"usage/install/#_2","title":"\u5355\u8282\u70b9\u96c6\u7fa4\u90e8\u7f72","text":"<p>\u53c2\u8003 <code>minimal</code> \u6837\u4f8b\u6a21\u677f</p> <p>\u53c2\u7167\u6a21\u677f\uff0c\u6211\u4eec\u5c06\u521b\u5efa\u4e00\u4e2a\u591a\u5408\u4e00\u7684\u5355\u8282\u70b9\u96c6\u7fa4\uff1a</p>"},{"location":"usage/install/#1-allinoneyml","title":"1. \u66f4\u65b0 <code>AllInOne.yml</code> \u4e2d\u7684\u5360\u4f4d\u7b26\u4e3a\u771f\u5b9e\u503c","text":"<ul> <li><code>&lt;IP1&gt;</code></li> <li><code>&lt;USERNAME&gt;</code></li> <li><code>&lt;PASSWORD&gt;</code></li> <li><code>&lt;TAG&gt;</code></li> </ul>"},{"location":"usage/install/#2-allinoneyml","title":"2. \u5e94\u7528 <code>AllInOne.yml</code>","text":"<pre><code>$ kubectl apply -f examples/install/1.minimal/\n</code></pre>"},{"location":"usage/install/#_3","title":"\u52a0\u901f\u5668\u6a21\u5f0f\u90e8\u7f72","text":"<p>\u53c2\u8003 <code>mirror</code> \u6837\u4f8b\u6a21\u677f</p>"},{"location":"usage/install/#1-2mirror-yaml","title":"1. \u66f4\u65b0 <code>2.mirror</code> \u76ee\u5f55\u4e2d yaml \u6e05\u5355\u7684\u5360\u4f4d\u7b26\u4e3a\u771f\u5b9e\u503c","text":"<ul> <li><code>&lt;IP1&gt;</code> / <code>&lt;IP2&gt;</code> ...</li> <li><code>&lt;USERNAME&gt;</code></li> <li><code>&lt;PASSWORD&gt;</code></li> <li><code>&lt;TAG&gt;</code></li> </ul>"},{"location":"usage/install/#2-2mirror-yaml","title":"2. \u5e94\u7528 <code>2.mirror</code> \u4e2d\u7684 yaml \u6e05\u5355","text":"<pre><code>$ kubectl apply -f examples/install/2.mirror/\n</code></pre>"},{"location":"usage/install/#3-varsconfcm","title":"3. \u52a0\u901f\u5668\u955c\u50cf\u8bbe\u7f6e\u8bf7\u89c1 <code>VarsConfCM</code>","text":"<p>\u672c\u4f8b\u4e2d\u4f7f\u7528\u5230\u7684\u52a0\u901f\u5668: * \u4e8c\u8fdb\u5236\u52a0\u901f\uff1apublic binary files mirror * \u955c\u50cf\u52a0\u901f\uff1apublic image mirror</p>"},{"location":"usage/install/#_4","title":"\u7eaf\u79bb\u7ebf\u6a21\u5f0f\u90e8\u7f72","text":"<p>\u53c2\u8003 <code>airgap</code> \u6837\u4f8b\u6a21\u677f</p> <p>\u8be6\u7ec6\u8bf7\u6d4f\u89c8 \u79bb\u7ebf\u573a\u666f\u7684\u4f7f\u7528</p>"},{"location":"usage/install/#ssh","title":"SSH\u79d8\u94a5\u6a21\u5f0f\u90e8\u7f72","text":"<p>\u8be6\u7ec6\u8bf7\u6d4f\u89c8 \u4f7f\u7528 SSH \u79d8\u94a5\u65b9\u5f0f\u90e8\u7f72 K8S \u96c6\u7fa4</p>"},{"location":"usage/mirror-install/","title":"Deploying a Cluster using Accelerated Mode","text":""},{"location":"usage/mirror-install/#prerequisites","title":"Prerequisites","text":"<ol> <li>You already have a standard Kubernetes cluster or a cluster provided by a cloud provider.</li> <li>The control node or cloud terminal for the cluster has the kubect tool installed.\u3002</li> <li>The kubean helm chart has been deployed on your cluster.</li> <li>The kubean \u9879\u76eehas been cloned to your local machine. If you haven't cloned kubean yet, you can do so by executing the following command:</li> </ol> <pre><code>$ git clone https://github.com/kubean-io/kubean.git\n</code></pre>"},{"location":"usage/mirror-install/#getting-started","title":"Getting Started","text":"<p>This tutorial will use the <code>kubean/example/2.mirror</code> file that you cloned to your local machine as an example template for demonstrating cluster deployment using accelerated mode.</p> <p>The <code>2.mirror</code> accelerated deployment template already contains built-in acceleration parameter configurations.  You only need to modify the host information and other relevant information in the two configuration template files, <code>HostsConfCM.yml</code> and <code>ClusterOperation.yml</code>, located in the /2.mirror file path.</p> The main configuration files and purposes inside the `2.mirror` file are as follows: <pre><code>    .2.mirror\n\u251c\u2500\u2500 Cluster.yml                        # The main configuration files and their purposes in the `2.mirror` file are as follows:\n\u251c\u2500\u2500 ClusterOperation.yml        # kubean version and task configuration\n\u251c\u2500\u2500 HostsConfCM.yml              # Node information configuration for the cluster to be built\n\u2514\u2500\u2500 VarsConfCM.yml                # Configuration for acceleration and other features\n</code></pre>"},{"location":"usage/mirror-install/#1configure-host-parameters-in-hostsconfcmyml","title":"1.Configure Host Parameters in HostsConfCM.yml","text":"<p>Navigate to the <code>kubean/examples/install/2.mirror/</code> path and edit the <code>HostsConfCM.yml</code>template for the node configuration information of the cluster to be built. Replace the following parameters with your actual parameters:</p> <ul> <li><code>&lt;IP1&gt;</code>\uff1aNode IP.</li> <li><code>&lt;USERNAME&gt;</code>\uff1a Username for logging in to the node. We recommend using root or a user with root privileges to log in.</li> <li><code>&lt;PASSWORD&gt;</code>\uff1aPassword for logging in to the node.</li> </ul> <p>For example, the following is an example HostsConfCM.yml file:</p>  HostsConfCM.yml Example <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\nname: online-hosts-conf\nnamespace: kubean-system\ndata:\nhosts.yml: |\nall:\nhosts:\nnode1:\nip: 10.6.175.10 # Your node IP\naccess_ip: 10.6.175.10 # Your node IP\nansible_host: 10.6.175.10 # Your node IP\nansible_connection: ssh\nansible_user: root # The username for logging into the node\nansible_password: password01 # The password for logging into the node\nnode2:\nip: 10.6.175.20 # Your node2 IP\naccess_ip: 10.6.175.20 # Your node2 IP\nansible_host: 10.6.175.20 # Your node2 IP\nansible_connection: ssh\nansible_user: root # The username for logging into the node2\nansible_password: password02 # The password for logging into the node2\nchildren:\nkube_control_plane: # Configuring the control node\nhosts:\nnode1:\nkube_node: # Configuring the working nodes of the cluster\nhosts:\nnode1:\nnode2:\netcd: # Configuring the ETCD nodes of the cluster\nhosts:\nnode1:\nk8s_cluster:\nchildren:\nkube_control_plane:\nkube_node:\ncalico_rr:\nhosts: {}\n</code></pre> <p>Execute the following command to edit the HostsConfCM.yml configuration template:</p> <pre><code>$ vi kubean/examples/install/2.mirror/HostsConfCM.yml\n</code></pre>"},{"location":"usage/mirror-install/#2-configure-kubean-task-parameters-in-clusteroperationyml","title":"2. Configure kubean Task Parameters in ClusterOperation.yml","text":"<p>Navigate to the <code>kubean/examples/install/2.mirror/</code> path and edit the <code>ClusterOperation.yml</code> template for the configuration information of the cluster to be built. Replace the following parameters with your actual parameters:</p> <ul> <li><code>&lt;TAG&gt;</code>: kubean image version. We recommend using the latest version.Refer to the kubean version list</li> </ul> <p>For example, the following is an example <code>ClusterOperation.yml</code> file:</p>  ClusterOperation.yml Example <pre><code>apiVersion: kubean.io/v1alpha1\nkind: ClusterOperation\nmetadata:\nname: cluster1-online-install-ops\nspec:\ncluster: cluster1-online\nimage: ghcr.m.daocloud.io/kubean-io/spray-job:v0.5.2 # kubean image version\nbackoffLimit: 0\nactionType: playbook\naction: cluster.yml\npreHook:\n- actionType: playbook\naction: ping.yml\n- actionType: playbook\naction: disable-firewalld.yml\npostHook:\n- actionType: playbook\naction: kubeconfig.yml\n- actionType: playbook\naction: cluster-info.yml\n</code></pre> <p>To edit the ClusterOperation.yml configuration template, run the following command:</p> <pre><code>$ vi kubean/examples/install/2.mirror/ClusterOperation.yml\n</code></pre>"},{"location":"usage/mirror-install/#3apply-all-configurations-under-the-2mirror-directory","title":"3.Apply all configurations under the 2.mirror directory","text":"<p>After completing the above steps and saving the HostsConfCM.yml and ClusterOperation.yml files, run the following command:</p> <pre><code>$ kubectl apply -f examples/install/2.mirror\n</code></pre> <p>With this, you have completed the deployment of a cluster using the acceleration mode.</p>"},{"location":"usage/scale-worknode/","title":"Scaling Cluster Worker Nodes","text":"<p>In the process of software development and operation, business growth often requires adding worker nodes to a cluster to meet the demand. For clusters deployed using kubean, we can use a declarative approach to quickly scale the cluster's worker nodes.</p> <p>In the <code>kubean/example/scale</code> directory cloned to your local machine, there is a sample template for scaling worker nodes:</p>  The main configuration files and purposes in the scale file are as follows:  <pre><code>    scale\n\u251c\u2500\u2500 1.addWorkNode                             # Template for adding worker nodes\n\u2502   \u251c\u2500\u2500 ClusterOperation.yml                       # kubean version and task configuration\n\u2502   \u2514\u2500\u2500 HostsConfCM.yml                            # configuration of current cluster node information\n\u2514\u2500\u2500 2.delWorkNode                             # Template for deleting worker nodes\n\u2502   \u251c\u2500\u2500 ClusterOperation.yml                       # kubean version and task configuration\n\u2502   \u2514\u2500\u2500 HostsConfCM.yml                             # configuration of current cluster node information\n</code></pre> <p>By observing the scaling configuration template in the <code>scale</code> file, it can be seen that scaling the cluster's worker nodes only requires executing two configuration files: <code>HostsConfCM.yml</code> and <code>ClusterOperation.yml</code>. You will need to replace the parameters such as the information of the new node with your actual parameters.</p> <p>Using the example of a single-node cluster deployed in all-in-one mode let's demonstrate how to scale the cluster's worker nodes.</p> <p>Note: Before scaling the cluster, you must have completed the deployment of a set of cluster using kubean.</p>"},{"location":"usage/scale-worknode/#scaling-worker-nodes","title":"Scaling Worker Nodes","text":""},{"location":"usage/scale-worknode/#1-add-new-node-host-parameters-to-hostsconfcmyml","title":"1. Add New Node Host Parameters to HostsConfCM.yml","text":"<p>To add a new node configuration to the ConfigMap named <code>mini-hosts-conf</code> in the existing all-in-one mode, we will add a new worker node <code>node2</code> based on the original main node <code>node1</code>.</p> <p>Specifically, we can go to the path <code>kubean/examples/scale/1.addWorkNode/</code>, edit the prepared node configuration ConfigMap template <code>HostsConfCM.yml</code>, and replace the following parameters with your actual parameters:</p> <ul> <li><code>&lt;IP2&gt;</code>: the IP address of the node.</li> <li><code>&lt;USERNAME&gt;</code>: the username to log in to the node. We recommend using either \"root\" or a user with root privileges.</li> <li><code>&lt;PASSWORD&gt;</code>: the password to log in to the node.</li> </ul> <p>The template content of <code>HostsConfCM.yml</code>  in the <code>kubean/examples/scale/1.addWorkNode/</code> path is as follows:</p>  HostsConfCM.yml \u6a21\u677f <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\nname: mini-hosts-conf\nnamespace: kubean-system\ndata:\nhosts.yml: |\nall:\nhosts:\nnode1:\nip: &lt;IP1&gt;\naccess_ip: &lt;IP1&gt;\nansible_host: &lt;IP1&gt;\nansible_connection: ssh\nansible_user: &lt;USERNAME&gt;\nansible_password: &lt;PASSWORD&gt;\nnode2:\nip: &lt;IP2&gt;\naccess_ip: &lt;IP2&gt;\nansible_host: &lt;IP2&gt;\nansible_connection: ssh\nansible_user: &lt;USERNAME&gt;\nansible_password: &lt;PASSWORD&gt;\nchildren:\nkube_control_plane:\nhosts:\nnode1:\nkube_node:\nhosts:\nnode1:\nnode2:\netcd:\nhosts:\nnode1:\nk8s_cluster:\nchildren:\nkube_control_plane:\nkube_node:\ncalico_rr:\nhosts: {}\n</code></pre> <p>Important Parameters:</p> <ul> <li><code>all.hosts.node1</code>: The original main node that already exists in the cluster.</li> <li><code>all.hosts.node2</code>: The worker node to be added to the cluster.</li> <li><code>all.children.kube_node.hosts</code>:  The group of worker nodes in the cluster.</li> </ul> <p>Example</p> Before Adding New NodeAfter Adding New Node <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\nname: mini-hosts-conf\nnamespace: kubean-system\ndata:\nhosts.yml: |\nall:\nhosts:\nnode1:\nip: 10.6.175.10 # Your node's IP\naccess_ip: 10.6.175.10 # Your node's IP\nansible_host: 10.6.175.10 # Your node's IP\nansible_connection: ssh\nansible_user: root # The username to log in to the node\nansible_password: password01 # The password to log in to the node\nchildren:\nkube_control_plane:\nhosts:\nnode1:\nkube_node:\nhosts:\nnode1:\netcd:\nhosts:\nnode1:\nk8s_cluster:\nchildren:\nkube_control_plane:\nkube_node:\ncalico_rr:\nhosts: {}\n</code></pre> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\nname: mini-hosts-conf\nnamespace: kubean-system\ndata:\nhosts.yml: |\nall:\nhosts:\nnode1:\nip: 10.6.175.10 # Your node's IP\naccess_ip: 10.6.175.10 # Your node's IP\nansible_host: 10.6.175.10 # Your node's IP\nansible_connection: ssh\nansible_user: root # The username to log in to the node\nansible_password: password01 # The password to log in to the node\nnode2:\nip: 10.6.175.20 # Your node's IP\naccess_ip: 10.6.175.20 # Your node's IP\nansible_host: 10.6.175.20 # Your node's IP\nansible_connection: ssh\nansible_user: root # The username to log in to the node\nansible_password: password01 # The password to log in to the node\nchildren:\nkube_control_plane:\nhosts:\nnode1:\nkube_node:\nhosts:\nnode1:\nnode2:\netcd:\nhosts:\nnode1:\nk8s_cluster:\nchildren:\nkube_control_plane:\nkube_node:\ncalico_rr:\nhosts: {}\n</code></pre>"},{"location":"usage/scale-worknode/#2-add-scaling-task-through-clusteroperationyml","title":"2. Add Scaling Task through ClusterOperation.yml","text":"<p>Go to the path <code>kubean/examples/scale/1.addWorkNode/</code> and edit the template <code>ClusterOperation.yml</code>,replacing the following parameter with your actual parameter:</p> <ul> <li><code>&lt;TAG&gt;</code>: the kubean image version. We recommend using the latest version. Refer to the kubean version list.</li> </ul> <p>The template content of <code>ClusterOperation.yml</code> in the <code>kubean/examples/scale/1.addWorkNode/</code> path is as follows:</p> <p><pre><code>apiVersion: kubean.io/v1alpha1\nkind: ClusterOperation\nmetadata:\nname: cluster-mini-awn-ops\nspec:\ncluster: cluster-mini\nimage: ghcr.m.daocloud.io/kubean-io/spray-job:&lt;TAG&gt; # Please replace &lt;TAG&gt; with the specified version, such as v0.4.9\nbackoffLimit: 0\nactionType: playbook\naction: scale.yml\nextraArgs: --limit=node2\n</code></pre> Important Parameters:</p> <ul> <li><code>spec.cluster</code>: specifies the name of the cluster to be scaled. The above example specifies the cluster named <code>cluster-mini</code> as the scaling target.</li> <li><code>spec.action:</code>: specifies the kubespray script for scaling the node, which is set to <code>scale.yml</code> here.</li> <li><code>spec.extraArgs</code>: specifies the limit of the nodes to be scaled. Here, the <code>--limit=</code> parameter is used to limit the scaling to the node2.</li> </ul> <p>For example, the following is an example of ClusterOperation.yml:</p>  ClusterOperation.yml Example <pre><code>---\napiVersion: kubean.io/v1alpha1\nkind: ClusterOperation\nmetadata:\nname: cluster-mini-awn-ops\nspec:\ncluster: cluster-mini\nimage: ghcr.m.daocloud.io/kubean-io/spray-job:v0.5.2\nbackoffLimit: 0\nactionType: playbook\naction: scale.yml\nextraArgs: --limit=node2\n</code></pre>"},{"location":"usage/scale-worknode/#3apply-all-configurations-under-scale1addworknode-folder","title":"3.Apply all configurations under <code>scale/1.addWorkNode</code> folder","text":"<p>After completing the above steps and saving the HostsConfCM.yml and ClusterOperation.yml files, run the following command:</p> <pre><code>$ kubectl apply -f examples/install/scale/1.addWorkNode/\n</code></pre> <p>At this point, you have completed the scaling of a working node in a cluster.</p>"},{"location":"usage/scale-worknode/#shrink-working-nodes","title":"Shrink Working Nodes","text":""},{"location":"usage/scale-worknode/#1-add-scaling-task-through-clusteroperationyml","title":"1. Add Scaling Task through ClusterOperation.yml","text":"<p>Go to the path <code>kubean/examples/scale/2.delWorkNode/</code> and edit the template <code>ClusterOperation.yml</code>, replacing the following parameter with your actual parameter:</p> <ul> <li><code>&lt;TAG&gt;</code>\uff1athe kubean image version. We recommend using the latest version. Refer to the kubean version list.</li> </ul> <p>The template content of <code>ClusterOperation.yml</code> in the <code>kubean/examples/scale/2.delWoorkNode/</code> path is as follows:</p> <p><pre><code>apiVersion: kubean.io/v1alpha1\nkind: ClusterOperation\nmetadata:\nname: cluster-mini-dwn-ops\nspec:\ncluster: cluster-mini\nimage: ghcr.m.daocloud.io/kubean-io/spray-job:&lt;TAG&gt; # Please replace &lt;TAG&gt; with the specified version, such as v0.4.9\nbackoffLimit: 0\nactionType: playbook\naction: remove-node.yml\nextraArgs: -e node=node2\n</code></pre> \u91cd\u8981\u53c2\u6570\uff1a</p> <ul> <li><code>spec.cluster</code>: specifies the name of the cluster to be scaled. The above example specifies the cluster named cluster-mini as the scaling target.</li> <li><code>spec.action</code>: specifies the kubespray script for scaling the node, which is set to remove-node.yml here.</li> <li><code>spec.extraArgs</code>: specifies the nodes to be scaled down. Here, the -e parameter is used to specify the node2 to be scaled down.</li> </ul> <p>For example, the following is an example of ClusterOperation.yml:</p>  ClusterOperation.yml Example <pre><code>apiVersion: kubean.io/v1alpha1\nkind: ClusterOperation\nmetadata:\nname: cluster-mini-dwn-ops\nspec:\ncluster: cluster-mini\nimage: ghcr.m.daocloud.io/kubean-io/spray-job:v0.5.2\nbackoffLimit: 0\nactionType: playbook\naction: remove-node.yml\nextraArgs: -e node=node2\n</code></pre>"},{"location":"usage/scale-worknode/#2apply-the-clusteroperation-scaling-task-list-under-the-scale2delworknode-directory","title":"2.Apply the ClusterOperation scaling task list under the <code>scale/2.delWorkNode</code> directory","text":"<p>After completing the above steps and saving the ClusterOperation.yml file, run the following command:</p> <pre><code>$ kubectl apply -f examples/install/scale/2.delWorkNode/ClusterOperation.yml\n</code></pre> <p>By default, enter the kubean-system namespace and check the execution status of the scaling task: <pre><code>$ kubectl -n kubean-system get pod | grep cluster-mini-dwn-ops\n</code></pre> To learn about the progress of the scaling task, you can view the logs of the pod.</p>"},{"location":"usage/scale-worknode/#3-delete-the-working-node-host-parameters-through-hostsconfcmyml","title":"3. Delete the working node host parameters through HostsConfCM.yml","text":"<p>We have executed the scaling task through the above two steps. After the scaling task is completed, node2 will be permanently removed from the existing cluster. Then, we need to complete the final step, which is to remove the <code>node2</code> information from the node configuration related Configmap.</p> <p>Go to the path <code>kubean/examples/scale/2.delWorkNode/</code> and edit the prepared node configuration template <code>HostsConfCM.yml</code> to remove the configuration of the working node that needs to be removed.</p> <p>The deleted parameters are as follows:</p> <ul> <li><code>all.hosts</code>: The node2 node access parameters.</li> <li><code>all.children.kube_node.hosts</code>: The node name node2.</li> </ul> <p>Example</p> Before removing the nodeAfter removing a node <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\nname: mini-hosts-conf\nnamespace: kubean-system\ndata:\nhosts.yml: |\nall:\nhosts:\nnode1:\nip: 10.6.175.10 # Your node's IP\naccess_ip: 10.6.175.10 # Your node's IP\nansible_host: 10.6.175.10 # Your node's IP\nansible_connection: ssh\nansible_user: root # The username to log in to the node\nansible_password: password01 # The password to log in to the node\nnode2:\nip: 10.6.175.20 # The IP address of node 2 is added\naccess_ip: 10.6.175.20 # The IP address of node 2 is added\nansible_host: 10.6.175.20 # The IP address of node 2 is added\nansible_connection: ssh\nansible_user: root # The username to log in to the node2\nansible_password: password01 # password to log in to the node2\nchildren:\nkube_control_plane:\nhosts:\nnode1:\nkube_node:\nhosts:\nnode1:\nnode2:\netcd:\nhosts:\nnode1:\nk8s_cluster:\nchildren:\nkube_control_plane:\nkube_node:\ncalico_rr:\nhosts: {}\n</code></pre> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\nname: mini-hosts-conf\nnamespace: kubean-system\ndata:\nhosts.yml: |\nall:\nhosts:\nnode1:\nip: 10.6.175.10 # Your node's IP\naccess_ip: 10.6.175.10 # Your node's IP\nansible_host: 10.6.175.10 # Your node's IP\nansible_connection: ssh\nansible_user: root # The username to log in to the node\nansible_password: password01 # The password to log in to the node\nchildren:\nkube_control_plane:\nhosts:\nnode1:\nkube_node:\nhosts:\nnode1:\netcd:\nhosts:\nnode1:\nk8s_cluster:\nchildren:\nkube_control_plane:\nkube_node:\ncalico_rr:\nhosts: {}\n</code></pre> <p>After completing the above steps and saving the HostsConfCM.yml file, execute the following command:</p> <pre><code>$ kubectl apply -f examples/install/scale/2.delWorkNode/HostsConfCM.yml\n</code></pre> <p>At this point, we have removed the node2 worker node from the cluster and cleaned up all the host information related to node2. The entire scaling down operation is now complete.</p>"},{"location":"usage/sshkey_deploy_cluster/","title":"Deploy Kubernetes clusters with SSH","text":"<p>Contents</p> <ul> <li>\u2713 1. Generate and distribute an SSH private key</li> <li>\u2713 2. Make a Secret with private key</li> <li>\u2713 3. Create a host configuration file</li> <li>\u2713 4. Provision parameters for cluster deployment</li> <li>\u2713 5. Prepare KuBean's CRDs</li> <li>\u2713 6. Deploy a cluster</li> </ul>"},{"location":"usage/sshkey_deploy_cluster/#generate-and-distribute-an-ssh-private-key","title":"Generate and distribute an SSH private key","text":"<ol> <li>Generate a pair of public-private keys with <code>ssh-keygen</code> command:</li> </ol> <pre><code>$ ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\" -f $HOME/.ssh/id_rsa\nGenerating public/private rsa key pair.\nCreated directory '/root/.ssh'.\nEnter passphrase (empty for no passphrase):\nEnter same passphrase again:\nYour identification has been saved in /root/.ssh/id_rsa.\nYour public key has been saved in /root/.ssh/id_rsa.pub.\nThe key fingerprint is:\nSHA256:oMqlhL8wLuYycOkUNXyiDso62C+ryNYc9k3LMDltQZs your_email@example.com\nThe keys randomart image is:\n+---[RSA 4096]----+\n|   .             |\n|    = ..         |\n|   o +o o        |\n|..o  . E         |\n|+o.oo o S        |\n|o==* = +         |\n|*=O o O .        |\n|@=++ . +         |\n|OBo+.            |\n+----[SHA256]-----+\n\n$ ls /root/.ssh/id_rsa* -lh\n-rw-------. 1 root root 1.7K Nov 10 03:47 /root/.ssh/id_rsa         # \u79c1\u94a5\n-rw-r--r--. 1 root root  408 Nov 10 03:47 /root/.ssh/id_rsa.pub     # \u516c\u94a5\n</code></pre> <ol> <li>Distribute the key pair to nodes of the cluster to be deployed:</li> </ol> <pre><code># for example, specify to distribute the public key to nodes `192.168.10.11` and `192.168.10.12`.\n$ declare -a IPS=(192.168.10.11 192.168.10.12)\n\n# traverse node IPs to distribute the public key (/root/.ssh/id_rsa.pub) with the presumptive account/password: root/kubean\n$ for ip in ${IPS[@]}; do sshpass -p \"kubean\" ssh-copy-id -i /root/.ssh/id_rsa.pub -o StrictHostKeyChecking=no root@$ip; done\n</code></pre>"},{"location":"usage/sshkey_deploy_cluster/#make-a-secret-with-private-key","title":"Make a Secret with private key","text":"<ol> <li>Generate a Secret for the private key with the following command:</li> </ol> <pre><code>$ kubectl -n kubean-system \\                            # specify namespace: kubean-system\ncreate secret generic sample-ssh-auth \\             # specify the name of Secret: sample-ssh-auth\n--type='kubernetes.io/ssh-auth' \\                   # specify the type of Secret: kubernetes.io/ssh-auth\n--from-file=ssh-privatekey=/root/.ssh/id_rsa \\      # specify the filepath of the ssh private key\n--dry-run=client -o yaml &gt; SSHAuthSec.yml           # specify the target path of the new Secret YAML\n</code></pre> <p>The expected <code>SSHAuthSec.yml</code> looks like:</p> <pre><code># SSHAuthSec.yml\napiVersion: v1\nkind: Secret\nmetadata:\ncreationTimestamp: null\nname: sample-ssh-auth\nnamespace: kubean-system\ntype: kubernetes.io/ssh-auth\ndata:\nssh-privatekey: LS0tLS1CRUdJTiBSU0EgUFJJVkFURSBLRVktLS0tLQpNSUlKS1FJQkFBS0NBZ0VBdWVDbC8rSng1b0RT...\n</code></pre>"},{"location":"usage/sshkey_deploy_cluster/#create-a-host-configuration-file","title":"Create a host configuration file","text":"<p>The <code>HostsConfCM.yml</code> file looks like:</p> <pre><code># HostsConfCM.yml\napiVersion: v1\nkind: ConfigMap\nmetadata:\nname: sample-hosts-conf\nnamespace: kubean-system\ndata:\nhosts.yml: |\nall:\nhosts:\nmaster:\nip: 192.168.10.11\naccess_ip: 192.168.10.11\nansible_host: 192.168.10.11\nworker:\nip: 192.168.10.12\naccess_ip: 192.168.10.12\nansible_host: 192.168.10.12\nchildren:\nkube_control_plane:\nhosts:\nmaster:\nkube_node:\nhosts:\nmaster:\nworker:\netcd:\nhosts:\nmaster:\nk8s_cluster:\nchildren:\nkube_control_plane:\nkube_node:\ncalico_rr:\nhosts: {}\n</code></pre> <p>Note: No need to include the account and password (<code>ansible_user</code> and <code>ansible_password</code>) because of logging in with the private key.</p>"},{"location":"usage/sshkey_deploy_cluster/#provision-parameters-for-cluster-deployment","title":"Provision parameters for cluster deployment","text":"<p>For contents of <code>VarsConfCM.yaml</code>, refer to demo vars conf.</p> <pre><code># VarsConfCM.yml\napiVersion: v1\nkind: ConfigMap\nmetadata:\nname: sample-vars-conf\nnamespace: kubean-system\ndata:\ngroup_vars.yml: |\ncontainer_manager: containerd\nkube_network_plugin: calico\nkube_network_plugin_multus: false\nkube_proxy_mode: iptables\nenable_nodelocaldns: false\netcd_deployment_type: kubeadm\nntp_enabled: true\n...\n</code></pre>"},{"location":"usage/sshkey_deploy_cluster/#prepare-kubeans-crds","title":"Prepare KuBean's CRDs","text":"<ul> <li>Example of a <code>Cluster</code> CR:</li> </ul> <pre><code># Cluster.yml\napiVersion: kubean.io/v1alpha1\nkind: Cluster\nmetadata:\nname: sample\nspec:\nhostsConfRef:\nnamespace: kubean-system\nname: sample-hosts-conf\nvarsConfRef:\nnamespace: kubean-system\nname: sample-vars-conf\nsshAuthRef:                   # key field: specifies the Secret of the ssh private key for cluster deployment\nnamespace: kubean-system\nname: sample-ssh-auth\n</code></pre> <ul> <li>Example of a <code>ClusterOperation</code> CR:</li> </ul> <pre><code># ClusterOperation.yml\napiVersion: kubean.io/v1alpha1\nkind: ClusterOperation\nmetadata:\nname: sample-create-cluster\nspec:\ncluster: sample\nimage: ghcr.m.daocloud.io/kubean-io/spray-job:latest\nbackoffLimit: 0\nactionType: playbook\naction: cluster.yml\npreHook:\n- actionType: playbook\naction: ping.yml\n- actionType: playbook\naction: disable-firewalld.yml\npostHook:\n- actionType: playbook\naction: kubeconfig.yml\n- actionType: playbook\naction: cluster-info.yml\n</code></pre>"},{"location":"usage/sshkey_deploy_cluster/#deploy-a-cluster","title":"Deploy a cluster","text":"<p>Suppose all our YAML manifests are stored in the <code>create_cluster</code> directory:</p> <pre><code>$ tree create_cluster/\ncreate_cluster\n\u251c\u2500\u2500 HostsConfCM.yml       # \u4e3b\u673a\u6e05\u5355\n\u251c\u2500\u2500 SSHAuthSec.yml        # SSH\u79c1\u94a5\n\u251c\u2500\u2500 VarsConfCM.yml        # \u96c6\u7fa4\u53c2\u6570\n\u251c\u2500\u2500 Cluster.yml           # Cluster CR\n\u2514\u2500\u2500 ClusterOperation.yml  # ClusterOperation CR\n</code></pre> <p>Deploy a cluster with <code>kubectl apply</code>:</p> <pre><code>kubectl apply -f create_cluster/\n</code></pre>"},{"location":"usage/uninstall/","title":"Cluster Uninstallation","text":"<p>This section will show you how to use kubean to uninstall a cluster. In the <code>kubean/example/uninstall</code> directory that you cloned to your local machine, there is a sample template for uninstalling a cluster:</p>  The main configuration files and their purposes in the uninstall directory are as follows: <pre><code>    uninstall\n\u251c\u2500\u2500 ClusterOperation.yml                # Uninstall cluster task\n</code></pre> <p>In the following example, we will use a single-node cluster deployed in all-in-one mode to demonstrate the cluster upgrade operation.</p> <p>Note: Before performing a cluster uninstallation, you must have completed the deployment of a cluster using kubean.</p>"},{"location":"usage/uninstall/#1-add-an-uninstallation-task","title":"1. Add an uninstallation task","text":"<p>Go to the <code>kubean/examples/uninstall/</code> directory and edit the template <code>ClusterOperation.yml</code>, replacing the following parameters with your actual parameters:</p> <ul> <li><code>&lt;TAG&gt;</code>\uff1aThe kubean image version. It is recommended to use the latest version.Refer to the kubean version list.</li> </ul> <p>The template content of <code>kubean/examples/uninstall/</code> <code>ClusterOperation.yml</code> path is as follows:</p> <p><pre><code>apiVersion: kubean.io/v1alpha1\nkind: ClusterOperation\nmetadata:\nname: cluster-mini-uninstall-ops\nspec:\ncluster: cluster-mini\nimage: ghcr.m.daocloud.io/kubean-io/spray-job:&lt;TAG&gt; # Please replace &lt;TAG&gt; with the specified version, such as v0.4.9\nbackoffLimit: 0\nactionType: playbook\naction: reset.yml\n</code></pre> Important Parameters:</p> <ul> <li><code>spec.cluster</code>: Specifies the name of the cluster to be uninstalled. In the example above, the cluster named <code>cluster-mini</code> is the target for uninstallation.</li> <li><code>spec.action:</code>\uff1a: Specifies the Kubespray playbook for uninstallation. Here it is set to <code>reset.yml</code>.</li> </ul>"},{"location":"usage/uninstall/#2apply-the-configuration-in-the-uninstall-directory","title":"2.Apply the Configuration in the uninstall Directory","text":"<p>After completing the above steps and saving the ClusterOperation.yml file, execute the following command:</p> <pre><code>$ kubectl apply -f examples/uninstall/\n</code></pre> <p>At this point, you have successfully uninstalled a cluster.</p>"},{"location":"usage/upgrade/","title":"Cluster Version Upgrade","text":"<p>This section will introduce how to upgrade the Kubernetes version of a cluster using kubean. The <code>kubean/example/upgrade</code> directory that you cloned locally provides a sample template for cluster version upgrades:</p>  The main configuration files and their purposes in the upgrade directory are as follows: <pre><code>    upgrade\n\u251c\u2500\u2500 ClusterOperation.yml                  # Upgrade cluster tasks\n\u2514\u2500\u2500 VarsConfCM.yml                        # Configuration parameters for cluster version upgrades\n</code></pre> <p>To demonstrate the process of upgrading a cluster version, we will use the example of a single node cluster deployed using the all-in-one mode.</p> <p>Note: that before upgrading the cluster version, you must have completed the deployment of a cluster using kubean.</p>"},{"location":"usage/upgrade/#1-add-an-upgrade-task","title":"1. Add an upgrade task","text":"<p>Go to the <code>kubean/examples/upgrade/</code> directory and edit the <code>ClusterOperation.yml</code> template. Replace the following parameters with your actual parameters:</p> <ul> <li><code>&lt;TAG&gt;</code>\uff1aThe version of the kubean image. We recommend using the latest version.Refer to the kubean version list.</li> </ul> <p>The template for <code>ClusterOperation.yml</code> in the <code>kubean/examples/upgrade/</code> directory is as follows:</p> <p><pre><code>apiVersion: kubean.io/v1alpha1\nkind: ClusterOperation\nmetadata:\nname: cluster-mini-upgrade-ops\nspec:\ncluster: cluster-mini\nimage: ghcr.m.daocloud.io/kubean-io/spray-job:&lt;TAG&gt; # Please replace &lt;TAG&gt; with the specified version, such as v0.4.9\nbackoffLimit: 0\nactionType: playbook\naction: upgrade-cluster.yml\n</code></pre> Important Parameters:</p> <ul> <li><code>spec.cluster</code>: Specifies the name of the cluster to be upgraded. In the above example, the cluster named <code>cluster-mini</code> is the upgrade target.</li> <li><code>spec.action:</code> Specifies the kubespray playbook related to the upgrade. Here it is set to <code>upgrade-cluster.yml</code>.</li> </ul>"},{"location":"usage/upgrade/#2-specify-the-upgraded-version-of-the-cluster","title":"2. Specify the upgraded version of the cluster","text":"<p>Go to the <code>kubean/examples/upgrade/</code> directory and edit the <code>VarsConfCM.yml</code> template. Specify the version of the cluster upgrade by configuring the <code>kube_version</code> parameter.</p> <p>The template for <code>VarsConfCM.yml</code> in the <code>kubean/examples/upgrade/</code> directory is as follows:</p> <p><pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\nname: mini-vars-conf\nnamespace: kubean-system\ndata:\ngroup_vars.yml: |\nkube_version: v1.25.8\n# upgrade_cluster_setup: true\n# upgrade_node_confirm: true\n# upgrade_node_pause_seconds: 60\n\ncontainer_manager: containerd\nkube_network_plugin: calico\netcd_deployment_type: kubeadm\n</code></pre> Important Parameters:</p> <ul> <li><code>kube_version</code>: Specifies the version of the cluster to be upgraded. In the above example, it is set to upgrade to k8s v1.25.8.</li> </ul> <p>Example</p> Before upgrading the versionAfter upgrading the version <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\nname: mini-vars-conf\nnamespace: kubean-system\ndata:\ngroup_vars.yml: |\nkube_version: v1.25.0\n# upgrade_cluster_setup: true\n# upgrade_node_confirm: true\n# upgrade_node_pause_seconds: 60\n\ncontainer_manager: containerd\nkube_network_plugin: calico\netcd_deployment_type: kubeadm\n</code></pre> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\nname: mini-vars-conf\nnamespace: kubean-system\ndata:\ngroup_vars.yml: |\nkube_version: v1.25.8\n# upgrade_cluster_setup: true\n# upgrade_node_confirm: true\n# upgrade_node_pause_seconds: 60\n\ncontainer_manager: containerd\nkube_network_plugin: calico\netcd_deployment_type: kubeadm\n</code></pre> <p>Bonus: kubean cluster version support mechanism:</p> kubean Version Recommended Kubernetes Version Supported Kubernetes Version Range v0.5.2 v1.25.4 - \"v1.27.2\"        - \"v1.26.5\"        - \"v1.26.4\"        - \"v1.26.3\"        - \"v1.26.2\"        - \"v1.26.1\"        - \"v1.26.0\"        - \"v1.25.10\"        - \"v1.25.9\"        - \"v1.25.8\"        - \"v1.25.7\"        - \"v1.25.6\"        - \"v1.25.5\"        - \"v1.25.4\"        - \"v1.25.3\"        - \"v1.25.2\"        - \"v1.25.1\"        - \"v1.25.0\" <p>For more detailed information about upgrading parameters, please refer to the kubespray documentation:Updating Kubernetes with Kubespray.</p>"},{"location":"usage/upgrade/#3apply-all-configurations-under-the-upgrade-directory","title":"3.Apply all configurations under the <code>upgrade</code> directory","text":"<p>After completing the above steps andsaving the ClusterOperation.yml and VarsConfCM.yml files, run the following command:</p> <pre><code>$ kubectl apply -f examples/upgrade/\n</code></pre> <p>With this, you have completed the upgrade of the Kubernetes version for a cluster.</p>"}]}